{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21672eba",
   "metadata": {},
   "source": [
    "# Notebook v4 – Registry Enrichment, Delta Features & Transition Model\n",
    "\n",
    "**Input:**  \n",
    "- `../data/meta/version_delta_features_live.csv` (output from v3)\n",
    "\n",
    "Each row in `version_delta_features_live.csv` represents a version transition:\n",
    "\n",
    "> (ecosystem, package_name, prev_version → version)\n",
    "\n",
    "with an existing label:\n",
    "\n",
    "- `y_malicious` – label for the **current** version.\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads `version_delta_features_live.csv` as the base **delta table**.\n",
    "2. Ensures labels (`y_malicious`, `prev_label_malicious`) are available.\n",
    "3. Fetches **PyPI** / **npm** registry metadata for all versions.\n",
    "4. Builds per-version **static size & density** features.\n",
    "5. Converts those static features into **delta/ratio features** per transition.\n",
    "6. Adds **registry-inspired derived features** (unified size, density proxies,\n",
    "   log-magnitude, sign, “large jump” flags).\n",
    "7. Performs **feature selection** with ANOVA F-test (`SelectKBest`).\n",
    "8. Trains:\n",
    "   - A **Random Forest** on all transitions.\n",
    "   - A **transition model** only on rows where `prev_label_malicious == 0`\n",
    "     (known-good → next version).\n",
    "9. Saves selected feature names to:\n",
    "   - `../data/meta/selected_delta_features_v4.csv`.\n",
    "\n",
    "The original v3 table (`version_delta_features_live.csv`) is the **only input**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6804bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 – Imports & configuration\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "META_DIR = Path(\"../data/meta\")\n",
    "DELTA_CSV = META_DIR / \"version_delta_features_live.csv\"\n",
    "LABELS_VERSION_CSV = META_DIR / \"labels_version.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e57763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded delta features: (717, 18)\n",
      "Columns: ['ecosystem', 'package_name', 'prev_version', 'version', 'y_malicious', 'delta_num_requires_dist', 'delta_summary_len', 'delta_description_len', 'delta_num_classifiers', 'delta_has_author', 'delta_has_license', 'delta_num_dependencies', 'delta_num_dev_dependencies', 'delta_num_scripts', 'delta_num_keywords', 'delta_version_len', 'delta_version_num_dots', 'delta_version_has_prerelease']\n",
      "\n",
      "Label distribution (current version, y_malicious):\n",
      "y_malicious\n",
      "0    453\n",
      "1    264\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[INFO] Reconstructing prev_label_malicious from labels_version.csv\n",
      "\n",
      "Label distribution (previous version, prev_label_malicious):\n",
      "prev_label_malicious\n",
      "NaN     710\n",
      "True      7\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecosystem</th>\n",
       "      <th>package_name</th>\n",
       "      <th>prev_version</th>\n",
       "      <th>version</th>\n",
       "      <th>y_malicious</th>\n",
       "      <th>delta_num_requires_dist</th>\n",
       "      <th>delta_summary_len</th>\n",
       "      <th>delta_description_len</th>\n",
       "      <th>delta_num_classifiers</th>\n",
       "      <th>delta_has_author</th>\n",
       "      <th>delta_has_license</th>\n",
       "      <th>delta_num_dependencies</th>\n",
       "      <th>delta_num_dev_dependencies</th>\n",
       "      <th>delta_num_scripts</th>\n",
       "      <th>delta_num_keywords</th>\n",
       "      <th>delta_version_len</th>\n",
       "      <th>delta_version_num_dots</th>\n",
       "      <th>delta_version_has_prerelease</th>\n",
       "      <th>prev_label_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.22.1-20250825143753</td>\n",
       "      <td>3.23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.23.0</td>\n",
       "      <td>3.23.1-20250827125749</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.23.1-20250827125749</td>\n",
       "      <td>3.24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.24.0</td>\n",
       "      <td>3.24.1-20250827130031</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-linter</td>\n",
       "      <td>3.22.1-20250825143753</td>\n",
       "      <td>3.23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ecosystem                      package_name           prev_version  \\\n",
       "0       npm  @accordproject/concerto-analysis  3.22.1-20250825143753   \n",
       "1       npm  @accordproject/concerto-analysis                 3.23.0   \n",
       "2       npm  @accordproject/concerto-analysis  3.23.1-20250827125749   \n",
       "3       npm  @accordproject/concerto-analysis                 3.24.0   \n",
       "4       npm    @accordproject/concerto-linter  3.22.1-20250825143753   \n",
       "\n",
       "                 version  y_malicious  delta_num_requires_dist  \\\n",
       "0                 3.23.0            0                      NaN   \n",
       "1  3.23.1-20250827125749            0                      NaN   \n",
       "2                 3.24.0            0                      NaN   \n",
       "3  3.24.1-20250827130031            1                      NaN   \n",
       "4                 3.23.0            0                      NaN   \n",
       "\n",
       "   delta_summary_len  delta_description_len  delta_num_classifiers  \\\n",
       "0                NaN                    0.0                    NaN   \n",
       "1                NaN                    0.0                    NaN   \n",
       "2                NaN                    0.0                    NaN   \n",
       "3                NaN                    0.0                    NaN   \n",
       "4                NaN                    0.0                    NaN   \n",
       "\n",
       "   delta_has_author  delta_has_license  delta_num_dependencies  \\\n",
       "0               NaN                NaN                     0.0   \n",
       "1               NaN                NaN                     0.0   \n",
       "2               NaN                NaN                     0.0   \n",
       "3               NaN                NaN                     0.0   \n",
       "4               NaN                NaN                     0.0   \n",
       "\n",
       "   delta_num_dev_dependencies  delta_num_scripts  delta_num_keywords  \\\n",
       "0                         0.0                0.0                 0.0   \n",
       "1                         0.0                0.0                 0.0   \n",
       "2                         0.0                0.0                 0.0   \n",
       "3                         0.0                0.0                 0.0   \n",
       "4                         0.0                0.0                 0.0   \n",
       "\n",
       "   delta_version_len  delta_version_num_dots  delta_version_has_prerelease  \\\n",
       "0              -15.0                     0.0                          -1.0   \n",
       "1               15.0                     0.0                           1.0   \n",
       "2              -15.0                     0.0                          -1.0   \n",
       "3               15.0                     0.0                           1.0   \n",
       "4              -15.0                     0.0                          -1.0   \n",
       "\n",
       "  prev_label_malicious  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 – Load base delta table (v3 output) and normalize labels\n",
    "\n",
    "delta_df = pd.read_csv(DELTA_CSV)\n",
    "print(f\"Loaded delta features: {delta_df.shape}\")\n",
    "print(\"Columns:\", delta_df.columns.tolist())\n",
    "\n",
    "# --- Normalize current-version label: y_malicious ----------------------\n",
    "if \"y_malicious\" not in delta_df.columns:\n",
    "    if \"label_malicious\" in delta_df.columns:\n",
    "        print(\"[INFO] Using label_malicious as y_malicious\")\n",
    "        delta_df[\"y_malicious\"] = delta_df[\"label_malicious\"].astype(int)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Expected column 'y_malicious' or 'label_malicious' not found in delta_df\"\n",
    "        )\n",
    "\n",
    "print(\"\\nLabel distribution (current version, y_malicious):\")\n",
    "print(delta_df[\"y_malicious\"].value_counts(dropna=False))\n",
    "\n",
    "# --- Ensure prev_label_malicious exists (for transition model) ---------\n",
    "if \"prev_label_malicious\" not in delta_df.columns:\n",
    "    if LABELS_VERSION_CSV.exists():\n",
    "        print(\"\\n[INFO] Reconstructing prev_label_malicious from labels_version.csv\")\n",
    "        labels_version = pd.read_csv(LABELS_VERSION_CSV)\n",
    "\n",
    "        # Try to detect malicious label column in labels_version\n",
    "        label_col_candidates = [c for c in labels_version.columns if \"malicious\" in c]\n",
    "        if not label_col_candidates:\n",
    "            raise ValueError(\n",
    "                \"labels_version.csv does not contain a malicious label column; \"\n",
    "                \"expected something like 'label_malicious' or 'y_malicious'.\"\n",
    "            )\n",
    "        lv_label_col = label_col_candidates[0]\n",
    "\n",
    "        expected = {\"ecosystem\", \"package_name\", \"version\"}\n",
    "        missing_lv = expected - set(labels_version.columns)\n",
    "        if missing_lv:\n",
    "            raise ValueError(\n",
    "                f\"labels_version.csv is missing columns: {missing_lv}. \"\n",
    "                \"Adjust the join logic accordingly.\"\n",
    "            )\n",
    "\n",
    "        labels_prev = labels_version.rename(\n",
    "            columns={\n",
    "                \"version\": \"prev_version\",\n",
    "                lv_label_col: \"prev_label_malicious\",\n",
    "            }\n",
    "        )[[\"ecosystem\", \"package_name\", \"prev_version\", \"prev_label_malicious\"]]\n",
    "\n",
    "        before_rows = len(delta_df)\n",
    "        delta_df = delta_df.merge(\n",
    "            labels_prev,\n",
    "            on=[\"ecosystem\", \"package_name\", \"prev_version\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        after_rows = len(delta_df)\n",
    "        if before_rows != after_rows:\n",
    "            print(\n",
    "                f\"[WARN] Row count changed when merging prev_label_malicious: \"\n",
    "                f\"{before_rows} -> {after_rows}. Check for key duplication.\"\n",
    "            )\n",
    "    else:\n",
    "        print(\n",
    "            \"\\n[WARN] labels_version.csv not found; \"\n",
    "            \"prev_label_malicious will remain unavailable.\"\n",
    "        )\n",
    "\n",
    "if \"prev_label_malicious\" in delta_df.columns:\n",
    "    print(\"\\nLabel distribution (previous version, prev_label_malicious):\")\n",
    "    print(delta_df[\"prev_label_malicious\"].value_counts(dropna=False))\n",
    "else:\n",
    "    print(\"\\n[WARN] prev_label_malicious is not present in delta_df.\")\n",
    "\n",
    "delta_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb08f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ecosystems present:\n",
      "ecosystem\n",
      "npm     568\n",
      "pypi    149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – HTTP session, caches, and key column names\n",
    "\n",
    "SESSION = requests.Session()\n",
    "HTTP_TIMEOUT = 10\n",
    "\n",
    "pypi_cache: Dict[tuple, Optional[Dict[str, Any]]] = {}\n",
    "npm_cache: Dict[tuple, Optional[Dict[str, Any]]] = {}\n",
    "\n",
    "ECO_COL = \"ecosystem\"\n",
    "PKG_COL = \"package_name\"\n",
    "VER_COL = \"version\"\n",
    "\n",
    "missing_keys = [c for c in [ECO_COL, PKG_COL, VER_COL, \"prev_version\"] if c not in delta_df.columns]\n",
    "if missing_keys:\n",
    "    raise ValueError(\n",
    "        f\"Expected columns {missing_keys} in delta_df but they are missing.\"\n",
    "    )\n",
    "\n",
    "print(\"\\nEcosystems present:\")\n",
    "print(delta_df[ECO_COL].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "522d68fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sample PyPI rows found: 149\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 – PyPI metadata fetch\n",
    "\n",
    "def fetch_pypi_release(name: str, version: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch PyPI metadata for a given project/version from /pypi/<project>/<version>/json.\n",
    "    Returns a dict with derived fields or None on failure.\n",
    "    \"\"\"\n",
    "    key = (name, version)\n",
    "    if key in pypi_cache:\n",
    "        return pypi_cache[key]\n",
    "\n",
    "    url = f\"https://pypi.org/pypi/{name}/{version}/json\"\n",
    "    try:\n",
    "        resp = SESSION.get(url, timeout=HTTP_TIMEOUT)\n",
    "        if resp.status_code != 200:\n",
    "            pypi_cache[key] = None\n",
    "            return None\n",
    "        data = resp.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] PyPI request failed for {name} {version}: {e}\")\n",
    "        pypi_cache[key] = None\n",
    "        return None\n",
    "\n",
    "    urls = data.get(\"urls\") or []\n",
    "    if not urls:\n",
    "        pypi_cache[key] = None\n",
    "        return None\n",
    "\n",
    "    # Prefer wheel, fallback to sdist, else first file\n",
    "    preferred = None\n",
    "    for f in urls:\n",
    "        if f.get(\"packagetype\") == \"bdist_wheel\":\n",
    "            preferred = f\n",
    "            break\n",
    "    if preferred is None:\n",
    "        for f in urls:\n",
    "            if f.get(\"packagetype\") == \"sdist\":\n",
    "                preferred = f\n",
    "                break\n",
    "    if preferred is None:\n",
    "        preferred = urls[0]\n",
    "\n",
    "    result = {\n",
    "        \"pypi_size_bytes\": preferred.get(\"size\"),\n",
    "        \"pypi_packagetype\": preferred.get(\"packagetype\"),\n",
    "        \"pypi_filename\": preferred.get(\"filename\"),\n",
    "        \"pypi_url\": preferred.get(\"url\"),\n",
    "    }\n",
    "    pypi_cache[key] = result\n",
    "    return result\n",
    "\n",
    "\n",
    "# Quick test on a few PyPI rows (if any)\n",
    "sample_pypi = delta_df[delta_df[ECO_COL] == \"pypi\"]\n",
    "print(f\"[INFO] Sample PyPI rows found: {len(sample_pypi)}\")\n",
    "# for _, row in sample_pypi.iterrows():\n",
    "#     info = fetch_pypi_release(row[PKG_COL], row[VER_COL])\n",
    "#     print(row[PKG_COL], row[VER_COL], \"->\", info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658a19a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sample npm rows found: 568\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 – npm metadata fetch\n",
    "\n",
    "def fetch_npm_version(name: str, version: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch npm registry metadata for a given package version from\n",
    "    https://registry.npmjs.org/<name>/<version>.\n",
    "    Returns a dict with derived fields or None on failure.\n",
    "    \"\"\"\n",
    "    key = (name, version)\n",
    "    if key in npm_cache:\n",
    "        return npm_cache[key]\n",
    "\n",
    "    url = f\"https://registry.npmjs.org/{name}/{version}\"\n",
    "    try:\n",
    "        resp = SESSION.get(url, timeout=HTTP_TIMEOUT)\n",
    "        if resp.status_code != 200:\n",
    "            npm_cache[key] = None\n",
    "            return None\n",
    "        data = resp.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] npm request failed for {name}@{version}: {e}\")\n",
    "        npm_cache[key] = None\n",
    "        return None\n",
    "\n",
    "    dist = data.get(\"dist\") or {}\n",
    "    result = {\n",
    "        \"npm_tarball_url\": dist.get(\"tarball\"),\n",
    "        \"npm_shasum\": dist.get(\"shasum\"),\n",
    "        \"npm_integrity\": dist.get(\"integrity\"),\n",
    "        \"npm_unpacked_size_bytes\": dist.get(\"unpackedSize\"),\n",
    "        \"npm_file_count\": dist.get(\"fileCount\"),\n",
    "    }\n",
    "    npm_cache[key] = result\n",
    "    return result\n",
    "\n",
    "\n",
    "# Quick test on a few npm rows (if any)\n",
    "sample_npm = delta_df[delta_df[ECO_COL] == \"npm\"]\n",
    "print(f\"[INFO] Sample npm rows found: {len(sample_npm)}\")\n",
    "# for _, row in sample_npm.iterrows(): \n",
    "#     info = fetch_npm_version(row[PKG_COL], row[VER_COL])\n",
    "#     print(row[PKG_COL], row[VER_COL], \"->\", info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1096bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Unique (ecosystem, package, version) to fetch: 627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff20dfa7aaf54449a03d504b0a52ebf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registry_versions shape: (627, 12)\n",
      "registry_versions columns: ['ecosystem', 'package_name', 'version', 'npm_tarball_url', 'npm_shasum', 'npm_integrity', 'npm_unpacked_size_bytes', 'npm_file_count', 'pypi_size_bytes', 'pypi_packagetype', 'pypi_filename', 'pypi_url']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecosystem</th>\n",
       "      <th>package_name</th>\n",
       "      <th>version</th>\n",
       "      <th>npm_tarball_url</th>\n",
       "      <th>npm_shasum</th>\n",
       "      <th>npm_integrity</th>\n",
       "      <th>npm_unpacked_size_bytes</th>\n",
       "      <th>npm_file_count</th>\n",
       "      <th>pypi_size_bytes</th>\n",
       "      <th>pypi_packagetype</th>\n",
       "      <th>pypi_filename</th>\n",
       "      <th>pypi_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.23.0</td>\n",
       "      <td>https://registry.npmjs.org/@accordproject/conc...</td>\n",
       "      <td>31a9a9f3a76ed8c36f254e71a722375f331d909b</td>\n",
       "      <td>sha512-43JFp937RXuoOvXO5ynk+r8tofVCVivkUpv8Oon...</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.23.1-20250827125749</td>\n",
       "      <td>https://registry.npmjs.org/@accordproject/conc...</td>\n",
       "      <td>745caacfefb84ac50cefc4d9337188f5f71f025d</td>\n",
       "      <td>sha512-TuGa38FxgFJNbVT/kx/BtzeNzOD5/8lFGmw5nkp...</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.24.0</td>\n",
       "      <td>https://registry.npmjs.org/@accordproject/conc...</td>\n",
       "      <td>2e352eae9f6a0ac7c7f4abf1a708c2177c8889bf</td>\n",
       "      <td>sha512-9zYvF0vX4iRS9L7/QC4N4s91YzXAiRiUzX4UR4k...</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.24.1-20250827130031</td>\n",
       "      <td>https://registry.npmjs.org/@accordproject/conc...</td>\n",
       "      <td>4226c5234d18b36b61a40a78112454d63516770a</td>\n",
       "      <td>sha512-Tbkv+SiXyO2NXBRjpbPCGfFecr3Rm5gAOuM2qfe...</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-linter</td>\n",
       "      <td>3.23.0</td>\n",
       "      <td>https://registry.npmjs.org/@accordproject/conc...</td>\n",
       "      <td>014bc2c5a1a42045f3fd7f3635ddd5ea576a135b</td>\n",
       "      <td>sha512-tQ23JwR69JRH5X8XAfGRtpFhPLlHucGa3YsgDRh...</td>\n",
       "      <td>71080.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ecosystem                      package_name                version  \\\n",
       "0       npm  @accordproject/concerto-analysis                 3.23.0   \n",
       "1       npm  @accordproject/concerto-analysis  3.23.1-20250827125749   \n",
       "2       npm  @accordproject/concerto-analysis                 3.24.0   \n",
       "3       npm  @accordproject/concerto-analysis  3.24.1-20250827130031   \n",
       "4       npm    @accordproject/concerto-linter                 3.23.0   \n",
       "\n",
       "                                     npm_tarball_url  \\\n",
       "0  https://registry.npmjs.org/@accordproject/conc...   \n",
       "1  https://registry.npmjs.org/@accordproject/conc...   \n",
       "2  https://registry.npmjs.org/@accordproject/conc...   \n",
       "3  https://registry.npmjs.org/@accordproject/conc...   \n",
       "4  https://registry.npmjs.org/@accordproject/conc...   \n",
       "\n",
       "                                 npm_shasum  \\\n",
       "0  31a9a9f3a76ed8c36f254e71a722375f331d909b   \n",
       "1  745caacfefb84ac50cefc4d9337188f5f71f025d   \n",
       "2  2e352eae9f6a0ac7c7f4abf1a708c2177c8889bf   \n",
       "3  4226c5234d18b36b61a40a78112454d63516770a   \n",
       "4  014bc2c5a1a42045f3fd7f3635ddd5ea576a135b   \n",
       "\n",
       "                                       npm_integrity  npm_unpacked_size_bytes  \\\n",
       "0  sha512-43JFp937RXuoOvXO5ynk+r8tofVCVivkUpv8Oon...                 147757.0   \n",
       "1  sha512-TuGa38FxgFJNbVT/kx/BtzeNzOD5/8lFGmw5nkp...                 147802.0   \n",
       "2  sha512-9zYvF0vX4iRS9L7/QC4N4s91YzXAiRiUzX4UR4k...                 147757.0   \n",
       "3  sha512-Tbkv+SiXyO2NXBRjpbPCGfFecr3Rm5gAOuM2qfe...                 147802.0   \n",
       "4  sha512-tQ23JwR69JRH5X8XAfGRtpFhPLlHucGa3YsgDRh...                  71080.0   \n",
       "\n",
       "   npm_file_count  pypi_size_bytes pypi_packagetype pypi_filename pypi_url  \n",
       "0            61.0              NaN              NaN           NaN      NaN  \n",
       "1            61.0              NaN              NaN           NaN      NaN  \n",
       "2            61.0              NaN              NaN           NaN      NaN  \n",
       "3            61.0              NaN              NaN           NaN      NaN  \n",
       "4            39.0              NaN              NaN           NaN      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 – Build per-version registry metadata table\n",
    "\n",
    "# Unique (ecosystem, package_name, version) for current versions\n",
    "current_versions = delta_df[[ECO_COL, PKG_COL, VER_COL]].drop_duplicates()\n",
    "\n",
    "# Unique combos for prev_version (rename to match VER_COL)\n",
    "prev_versions = (\n",
    "    delta_df[[ECO_COL, PKG_COL, \"prev_version\"]]\n",
    "    .rename(columns={\"prev_version\": VER_COL})\n",
    "    .dropna(subset=[VER_COL])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "all_versions = (\n",
    "    pd.concat([current_versions, prev_versions], ignore_index=True)\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Unique (ecosystem, package, version) to fetch: {len(all_versions)}\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for _, row in tqdm(all_versions.iterrows(), total=len(all_versions)):\n",
    "    ecos = row[ECO_COL]\n",
    "    name = row[PKG_COL]\n",
    "    ver = row[VER_COL]\n",
    "\n",
    "    rec: Dict[str, Any] = {\n",
    "        ECO_COL: ecos,\n",
    "        PKG_COL: name,\n",
    "        VER_COL: ver,\n",
    "    }\n",
    "\n",
    "    meta: Optional[Dict[str, Any]] = None\n",
    "    if ecos == \"pypi\":\n",
    "        meta = fetch_pypi_release(name, ver)\n",
    "    elif ecos == \"npm\":\n",
    "        meta = fetch_npm_version(name, ver)\n",
    "    else:\n",
    "        meta = None\n",
    "\n",
    "    if meta is not None:\n",
    "        rec.update(meta)\n",
    "\n",
    "    records.append(rec)\n",
    "\n",
    "registry_versions = pd.DataFrame(records)\n",
    "print(\"registry_versions shape:\", registry_versions.shape)\n",
    "print(\"registry_versions columns:\", registry_versions.columns.tolist())\n",
    "registry_versions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b43733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sample of registry_versions with static features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecosystem</th>\n",
       "      <th>package_name</th>\n",
       "      <th>version</th>\n",
       "      <th>pypi_size_bytes</th>\n",
       "      <th>npm_unpacked_size_bytes</th>\n",
       "      <th>npm_file_count</th>\n",
       "      <th>static_size_uncompressed_bytes</th>\n",
       "      <th>static_size_compressed_bytes</th>\n",
       "      <th>entropy_ratio_size</th>\n",
       "      <th>entropy_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2422.245902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.23.1-20250827125749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2422.983607</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2422.245902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-analysis</td>\n",
       "      <td>3.24.1-20250827130031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2422.983607</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>npm</td>\n",
       "      <td>@accordproject/concerto-linter</td>\n",
       "      <td>3.23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71080.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>71080.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1822.564103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ecosystem                      package_name                version  \\\n",
       "0       npm  @accordproject/concerto-analysis                 3.23.0   \n",
       "1       npm  @accordproject/concerto-analysis  3.23.1-20250827125749   \n",
       "2       npm  @accordproject/concerto-analysis                 3.24.0   \n",
       "3       npm  @accordproject/concerto-analysis  3.24.1-20250827130031   \n",
       "4       npm    @accordproject/concerto-linter                 3.23.0   \n",
       "\n",
       "   pypi_size_bytes  npm_unpacked_size_bytes  npm_file_count  \\\n",
       "0              NaN                 147757.0            61.0   \n",
       "1              NaN                 147802.0            61.0   \n",
       "2              NaN                 147757.0            61.0   \n",
       "3              NaN                 147802.0            61.0   \n",
       "4              NaN                  71080.0            39.0   \n",
       "\n",
       "   static_size_uncompressed_bytes  static_size_compressed_bytes  \\\n",
       "0                        147757.0                           NaN   \n",
       "1                        147802.0                           NaN   \n",
       "2                        147757.0                           NaN   \n",
       "3                        147802.0                           NaN   \n",
       "4                         71080.0                           NaN   \n",
       "\n",
       "   entropy_ratio_size  entropy_indicator  \n",
       "0         2422.245902                0.0  \n",
       "1         2422.983607                0.0  \n",
       "2         2422.245902                0.0  \n",
       "3         2422.983607                0.0  \n",
       "4         1822.564103                0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 – Per-version static size & density features (with column aliases)\n",
    "\n",
    "reg_cols = set(registry_versions.columns)\n",
    "\n",
    "# --- Alias raw registry columns to the names v4 expects ----------------\n",
    "# PyPI: some older code may have left this as just \"size\"\n",
    "if \"pypi_size_bytes\" not in registry_versions.columns:\n",
    "    if \"size\" in registry_versions.columns:\n",
    "        print(\"[INFO] Using registry_versions['size'] as pypi_size_bytes\")\n",
    "        registry_versions[\"pypi_size_bytes\"] = registry_versions[\"size\"]\n",
    "    else:\n",
    "        print(\"[WARN] No pypi_size_bytes or size column found; PyPI size deltas will be NaN\")\n",
    "\n",
    "# npm: in case of raw names \"unpackedSize\" / \"fileCount\"\n",
    "if \"npm_unpacked_size_bytes\" not in registry_versions.columns and \"unpackedSize\" in registry_versions.columns:\n",
    "    print(\"[INFO] Using registry_versions['unpackedSize'] as npm_unpacked_size_bytes\")\n",
    "    registry_versions[\"npm_unpacked_size_bytes\"] = registry_versions[\"unpackedSize\"]\n",
    "\n",
    "if \"npm_file_count\" not in registry_versions.columns and \"fileCount\" in registry_versions.columns:\n",
    "    print(\"[INFO] Using registry_versions['fileCount'] as npm_file_count\")\n",
    "    registry_versions[\"npm_file_count\"] = registry_versions[\"fileCount\"]\n",
    "\n",
    "# Refresh set of columns after aliasing\n",
    "reg_cols = set(registry_versions.columns)\n",
    "\n",
    "# --- Compute unified static sizes -------------------------------------\n",
    "def choose_static_uncompressed(row: pd.Series) -> float:\n",
    "    npm_size = row.get(\"npm_unpacked_size_bytes\", np.nan)\n",
    "    pypi_size = row.get(\"pypi_size_bytes\", np.nan)\n",
    "    if pd.notna(npm_size):\n",
    "        return float(npm_size)\n",
    "    if pd.notna(pypi_size):\n",
    "        return float(pypi_size)\n",
    "    return np.nan\n",
    "\n",
    "registry_versions[\"static_size_uncompressed_bytes\"] = registry_versions.apply(\n",
    "    choose_static_uncompressed, axis=1\n",
    ")\n",
    "\n",
    "# \"Compressed\" size – only really for PyPI, if present\n",
    "registry_versions[\"static_size_compressed_bytes\"] = registry_versions.get(\n",
    "    \"pypi_size_bytes\", np.nan\n",
    ")\n",
    "\n",
    "# Unified \"package size\" alias\n",
    "registry_versions[\"static_pkg_size_bytes\"] = registry_versions[\n",
    "    \"static_size_uncompressed_bytes\"\n",
    "]\n",
    "\n",
    "# --- Entropy / density-like proxy: bytes per file ---------------------\n",
    "def compute_entropy_ratio(row: pd.Series) -> float:\n",
    "    size = row.get(\"static_pkg_size_bytes\", np.nan)\n",
    "    count = row.get(\"npm_file_count\", np.nan)\n",
    "    if pd.isna(size) or pd.isna(count) or count <= 0:\n",
    "        return np.nan\n",
    "    return float(size) / float(count)\n",
    "\n",
    "registry_versions[\"entropy_ratio_size\"] = registry_versions.apply(\n",
    "    compute_entropy_ratio, axis=1\n",
    ")\n",
    "\n",
    "DENSITY_THRESHOLD = 5000.0\n",
    "registry_versions[\"entropy_indicator\"] = np.where(\n",
    "    registry_versions[\"entropy_ratio_size\"] >= DENSITY_THRESHOLD, 1.0, 0.0\n",
    ")\n",
    "\n",
    "# ---- Safe debug view: only show columns that actually exist -----------\n",
    "candidate_cols = [\n",
    "    ECO_COL,\n",
    "    PKG_COL,\n",
    "    VER_COL,\n",
    "    \"pypi_size_bytes\",\n",
    "    \"npm_unpacked_size_bytes\",\n",
    "    \"npm_file_count\",\n",
    "    \"static_size_uncompressed_bytes\",\n",
    "    \"static_size_compressed_bytes\",\n",
    "    \"entropy_ratio_size\",\n",
    "    \"entropy_indicator\",\n",
    "]\n",
    "\n",
    "cols_to_show = [c for c in candidate_cols if c in registry_versions.columns]\n",
    "\n",
    "print(\"[INFO] Sample of registry_versions with static features:\")\n",
    "registry_versions[cols_to_show].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad6e50f15144209afdc648b98ef890c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_static_df shape: (717, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>static_size_prev_uncompressed_bytes</th>\n",
       "      <th>static_size_curr_uncompressed_bytes</th>\n",
       "      <th>static_size_delta_vs_prev</th>\n",
       "      <th>static_size_ratio_vs_prev</th>\n",
       "      <th>ratio_static_size_uncompressed_bytes</th>\n",
       "      <th>delta_pypi_size_bytes</th>\n",
       "      <th>ratio_pypi_size_bytes</th>\n",
       "      <th>delta_npm_unpacked_size_bytes</th>\n",
       "      <th>ratio_npm_unpacked_size_bytes</th>\n",
       "      <th>delta_npm_file_count</th>\n",
       "      <th>ratio_npm_file_count</th>\n",
       "      <th>delta_entropy_ratio_size</th>\n",
       "      <th>ratio_entropy_ratio_size</th>\n",
       "      <th>delta_entropy_indicator</th>\n",
       "      <th>ratio_entropy_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147802.0</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737705</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147757.0</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147802.0</td>\n",
       "      <td>147757.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737705</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147757.0</td>\n",
       "      <td>147802.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122945.0</td>\n",
       "      <td>71080.0</td>\n",
       "      <td>-51865.0</td>\n",
       "      <td>0.578145</td>\n",
       "      <td>0.578145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-51865.0</td>\n",
       "      <td>0.578145</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>-98.451522</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   static_size_prev_uncompressed_bytes  static_size_curr_uncompressed_bytes  \\\n",
       "0                             147802.0                             147757.0   \n",
       "1                             147757.0                             147802.0   \n",
       "2                             147802.0                             147757.0   \n",
       "3                             147757.0                             147802.0   \n",
       "4                             122945.0                              71080.0   \n",
       "\n",
       "   static_size_delta_vs_prev  static_size_ratio_vs_prev  \\\n",
       "0                      -45.0                   0.999696   \n",
       "1                       45.0                   1.000305   \n",
       "2                      -45.0                   0.999696   \n",
       "3                       45.0                   1.000305   \n",
       "4                   -51865.0                   0.578145   \n",
       "\n",
       "   ratio_static_size_uncompressed_bytes  delta_pypi_size_bytes  \\\n",
       "0                              0.999696                    NaN   \n",
       "1                              1.000305                    NaN   \n",
       "2                              0.999696                    NaN   \n",
       "3                              1.000305                    NaN   \n",
       "4                              0.578145                    NaN   \n",
       "\n",
       "   ratio_pypi_size_bytes  delta_npm_unpacked_size_bytes  \\\n",
       "0                    NaN                          -45.0   \n",
       "1                    NaN                           45.0   \n",
       "2                    NaN                          -45.0   \n",
       "3                    NaN                           45.0   \n",
       "4                    NaN                       -51865.0   \n",
       "\n",
       "   ratio_npm_unpacked_size_bytes  delta_npm_file_count  ratio_npm_file_count  \\\n",
       "0                       0.999696                   0.0              1.000000   \n",
       "1                       1.000305                   0.0              1.000000   \n",
       "2                       0.999696                   0.0              1.000000   \n",
       "3                       1.000305                   0.0              1.000000   \n",
       "4                       0.578145                 -25.0              0.609375   \n",
       "\n",
       "   delta_entropy_ratio_size  ratio_entropy_ratio_size  \\\n",
       "0                 -0.737705                  0.999696   \n",
       "1                  0.737705                  1.000305   \n",
       "2                 -0.737705                  0.999696   \n",
       "3                  0.737705                  1.000305   \n",
       "4                -98.451522                  0.948750   \n",
       "\n",
       "   delta_entropy_indicator  ratio_entropy_indicator  \n",
       "0                      0.0                      NaN  \n",
       "1                      0.0                      NaN  \n",
       "2                      0.0                      NaN  \n",
       "3                      0.0                      NaN  \n",
       "4                      0.0                      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9 – Build per-transition static deltas & ratios (robust to missing columns)\n",
    "\n",
    "STATIC_BASE_COLS = [\n",
    "    \"static_size_uncompressed_bytes\",\n",
    "    \"static_size_compressed_bytes\",\n",
    "    \"pypi_size_bytes\",             # may be missing if no PyPI data\n",
    "    \"npm_unpacked_size_bytes\",     # may be missing if aliasing didn't happen\n",
    "    \"npm_file_count\",\n",
    "    \"entropy_ratio_size\",\n",
    "    \"entropy_indicator\",\n",
    "]\n",
    "\n",
    "key_cols = [ECO_COL, PKG_COL, VER_COL]\n",
    "\n",
    "# Only select the static columns that actually exist in registry_versions\n",
    "available_base_cols = [c for c in STATIC_BASE_COLS if c in registry_versions.columns]\n",
    "missing_base_cols = [c for c in STATIC_BASE_COLS if c not in registry_versions.columns]\n",
    "\n",
    "if missing_base_cols:\n",
    "    print(f\"[INFO] Skipping missing static base cols in registry_versions: {missing_base_cols}\")\n",
    "\n",
    "static_map: Dict[tuple, Dict[str, Any]] = {}\n",
    "\n",
    "for _, r in registry_versions[key_cols + available_base_cols].iterrows():\n",
    "    key = (r[ECO_COL], r[PKG_COL], r[VER_COL])\n",
    "\n",
    "    # Build a dict for *all* expected STATIC_BASE_COLS, filling missing ones with NaN\n",
    "    stats = {}\n",
    "    for col in STATIC_BASE_COLS:\n",
    "        stats[col] = r.get(col, np.nan)\n",
    "    static_map[key] = stats\n",
    "\n",
    "\n",
    "def safe_ratio(num: float, den: float) -> float:\n",
    "    if den is None or (isinstance(den, float) and (np.isnan(den) or den == 0.0)):\n",
    "        return np.nan\n",
    "    return num / den\n",
    "\n",
    "\n",
    "delta_static_records = []\n",
    "\n",
    "for _, r in tqdm(delta_df.iterrows(), total=len(delta_df)):\n",
    "    ecos = r[ECO_COL]\n",
    "    name = r[PKG_COL]\n",
    "    ver_curr = r[VER_COL]\n",
    "    ver_prev = r[\"prev_version\"]\n",
    "\n",
    "    curr_stats = static_map.get((ecos, name, ver_curr), {})\n",
    "    prev_stats = static_map.get((ecos, name, ver_prev), {})\n",
    "\n",
    "    rec: Dict[str, Any] = {}\n",
    "\n",
    "    # ---- Unified uncompressed static size ---------------------------------\n",
    "    curr_uncomp = float(curr_stats.get(\"static_size_uncompressed_bytes\", np.nan))\n",
    "    prev_uncomp = float(prev_stats.get(\"static_size_uncompressed_bytes\", np.nan))\n",
    "\n",
    "    rec[\"static_size_prev_uncompressed_bytes\"] = prev_uncomp\n",
    "    rec[\"static_size_curr_uncompressed_bytes\"] = curr_uncomp\n",
    "\n",
    "    if np.isnan(curr_uncomp) or np.isnan(prev_uncomp):\n",
    "        rec[\"static_size_delta_vs_prev\"] = np.nan\n",
    "        rec[\"static_size_ratio_vs_prev\"] = np.nan\n",
    "        rec[\"ratio_static_size_uncompressed_bytes\"] = np.nan\n",
    "    else:\n",
    "        rec[\"static_size_delta_vs_prev\"] = curr_uncomp - prev_uncomp\n",
    "        ratio = safe_ratio(curr_uncomp, prev_uncomp)\n",
    "        rec[\"static_size_ratio_vs_prev\"] = ratio\n",
    "        rec[\"ratio_static_size_uncompressed_bytes\"] = ratio\n",
    "\n",
    "    # ---- PyPI size delta/ratio (will just be NaN if you have no PyPI) -----\n",
    "    curr_pypi = float(curr_stats.get(\"pypi_size_bytes\", np.nan))\n",
    "    prev_pypi = float(prev_stats.get(\"pypi_size_bytes\", np.nan))\n",
    "\n",
    "    if np.isnan(curr_pypi) or np.isnan(prev_pypi):\n",
    "        rec[\"delta_pypi_size_bytes\"] = np.nan\n",
    "        rec[\"ratio_pypi_size_bytes\"] = np.nan\n",
    "    else:\n",
    "        rec[\"delta_pypi_size_bytes\"] = curr_pypi - prev_pypi\n",
    "        rec[\"ratio_pypi_size_bytes\"] = safe_ratio(curr_pypi, prev_pypi)\n",
    "\n",
    "    # ---- npm unpacked size delta/ratio ------------------------------------\n",
    "    curr_npm_size = float(curr_stats.get(\"npm_unpacked_size_bytes\", np.nan))\n",
    "    prev_npm_size = float(prev_stats.get(\"npm_unpacked_size_bytes\", np.nan))\n",
    "\n",
    "    if np.isnan(curr_npm_size) or np.isnan(prev_npm_size):\n",
    "        rec[\"delta_npm_unpacked_size_bytes\"] = np.nan\n",
    "        rec[\"ratio_npm_unpacked_size_bytes\"] = np.nan\n",
    "    else:\n",
    "        rec[\"delta_npm_unpacked_size_bytes\"] = curr_npm_size - prev_npm_size\n",
    "        rec[\"ratio_npm_unpacked_size_bytes\"] = safe_ratio(\n",
    "            curr_npm_size, prev_npm_size\n",
    "        )\n",
    "\n",
    "    # ---- npm file count delta/ratio ---------------------------------------\n",
    "    curr_npm_files = float(curr_stats.get(\"npm_file_count\", np.nan))\n",
    "    prev_npm_files = float(prev_stats.get(\"npm_file_count\", np.nan))\n",
    "\n",
    "    if np.isnan(curr_npm_files) or np.isnan(prev_npm_files):\n",
    "        rec[\"delta_npm_file_count\"] = np.nan\n",
    "        rec[\"ratio_npm_file_count\"] = np.nan\n",
    "    else:\n",
    "        rec[\"delta_npm_file_count\"] = curr_npm_files - prev_npm_files\n",
    "        rec[\"ratio_npm_file_count\"] = safe_ratio(curr_npm_files, prev_npm_files)\n",
    "\n",
    "    # ---- Entropy ratio delta/ratio ----------------------------------------\n",
    "    curr_entropy = float(curr_stats.get(\"entropy_ratio_size\", np.nan))\n",
    "    prev_entropy = float(prev_stats.get(\"entropy_ratio_size\", np.nan))\n",
    "\n",
    "    if np.isnan(curr_entropy) or np.isnan(prev_entropy):\n",
    "        rec[\"delta_entropy_ratio_size\"] = np.nan\n",
    "        rec[\"ratio_entropy_ratio_size\"] = np.nan\n",
    "    else:\n",
    "        rec[\"delta_entropy_ratio_size\"] = curr_entropy - prev_entropy\n",
    "        rec[\"ratio_entropy_ratio_size\"] = safe_ratio(curr_entropy, prev_entropy)\n",
    "\n",
    "    # ---- Entropy indicator delta/ratio ------------------------------------\n",
    "    curr_indicator = float(curr_stats.get(\"entropy_indicator\", np.nan))\n",
    "    prev_indicator = float(prev_stats.get(\"entropy_indicator\", np.nan))\n",
    "\n",
    "    if np.isnan(curr_indicator) or np.isnan(prev_indicator):\n",
    "        rec[\"delta_entropy_indicator\"] = np.nan\n",
    "        rec[\"ratio_entropy_indicator\"] = np.nan\n",
    "    else:\n",
    "        rec[\"delta_entropy_indicator\"] = curr_indicator - prev_indicator\n",
    "        rec[\"ratio_entropy_indicator\"] = safe_ratio(curr_indicator, prev_indicator)\n",
    "\n",
    "    delta_static_records.append(rec)\n",
    "\n",
    "delta_static_df = pd.DataFrame(delta_static_records, index=delta_df.index)\n",
    "print(\"delta_static_df shape:\", delta_static_df.shape)\n",
    "delta_static_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "694fdfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched delta_df shape: (717, 34)\n",
      "delta_df columns (first 40): ['ecosystem', 'package_name', 'prev_version', 'version', 'y_malicious', 'delta_num_requires_dist', 'delta_summary_len', 'delta_description_len', 'delta_num_classifiers', 'delta_has_author', 'delta_has_license', 'delta_num_dependencies', 'delta_num_dev_dependencies', 'delta_num_scripts', 'delta_num_keywords', 'delta_version_len', 'delta_version_num_dots', 'delta_version_has_prerelease', 'prev_label_malicious', 'static_size_prev_uncompressed_bytes', 'static_size_curr_uncompressed_bytes', 'static_size_delta_vs_prev', 'static_size_ratio_vs_prev', 'ratio_static_size_uncompressed_bytes', 'delta_pypi_size_bytes', 'ratio_pypi_size_bytes', 'delta_npm_unpacked_size_bytes', 'ratio_npm_unpacked_size_bytes', 'delta_npm_file_count', 'ratio_npm_file_count', 'delta_entropy_ratio_size', 'ratio_entropy_ratio_size', 'delta_entropy_indicator', 'ratio_entropy_indicator']\n",
      "[INFO] Saved v4-enriched delta table to ..\\data\\meta\\version_delta_features_v4.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 – Merge new static-delta features into delta_df\n",
    "\n",
    "delta_df = pd.concat(\n",
    "    [delta_df.reset_index(drop=True), delta_static_df.reset_index(drop=True)],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"Enriched delta_df shape:\", delta_df.shape)\n",
    "print(\"delta_df columns (first 40):\", delta_df.columns.tolist()[:40])\n",
    "\n",
    "# (Optional) save a v4-enriched version; keep v3 output intact\n",
    "out_delta_v4_csv = META_DIR / \"version_delta_features_v4.csv\"\n",
    "delta_df.to_csv(out_delta_v4_csv, index=False)\n",
    "print(f\"[INFO] Saved v4-enriched delta table to {out_delta_v4_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88425a99",
   "metadata": {},
   "source": [
    "## Cell 11 – Registry-inspired derived features\n",
    "\n",
    "In this step we derive **registry-style anomaly features** from existing delta / ratio columns:\n",
    "\n",
    "- **Unified size delta / ratio**  \n",
    "  - `delta_unified_size_bytes` picks the first available size delta per row  \n",
    "    (e.g., offline static size delta, PyPI size delta, npm unpacked size delta).  \n",
    "  - `ratio_unified_size` does the same for multiplicative size change.  \n",
    "  - This gives the model a single “best” view of **how much the package size changed** between versions, independent of ecosystem or data source.\n",
    "\n",
    "- **Density / “bytes per file” proxies**  \n",
    "  - `ratio_npm_bytes_per_file_proxy`, `delta_npm_bytes_per_file_proxy`, and `delta_unified_density_proxy` approximate changes in **bytes per file**.  \n",
    "  - These act as weak proxies for “packedness” or density: large size increases without similar file-count increases may indicate new blobs, embedded payloads, or obfuscated content.\n",
    "\n",
    "All features are made **NaN-safe** and given neutral defaults so they can be used directly in feature selection and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb33acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 delta_* features and 6 ratio_* features\n",
      "Density / entropy-like columns now present: ['ratio_npm_bytes_per_file_proxy', 'delta_npm_bytes_per_file_proxy', 'delta_unified_density_proxy']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_npm_bytes_per_file_proxy</th>\n",
       "      <th>delta_npm_bytes_per_file_proxy</th>\n",
       "      <th>delta_unified_density_proxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948750</td>\n",
       "      <td>2074.6</td>\n",
       "      <td>2074.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratio_npm_bytes_per_file_proxy  delta_npm_bytes_per_file_proxy  \\\n",
       "0                        0.999696                             0.0   \n",
       "1                        1.000305                             0.0   \n",
       "2                        0.999696                             0.0   \n",
       "3                        1.000305                             0.0   \n",
       "4                        0.948750                          2074.6   \n",
       "\n",
       "   delta_unified_density_proxy  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                       2074.6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 11 – Registry-inspired derived features (all delta / ratio based)\n",
    "\n",
    "cols = set(delta_df.columns)\n",
    "\n",
    "delta_cols = [c for c in delta_df.columns if c.startswith(\"delta_\")]\n",
    "ratio_cols = [c for c in delta_df.columns if c.startswith(\"ratio_\")]\n",
    "\n",
    "print(f\"Found {len(delta_cols)} delta_* features and {len(ratio_cols)} ratio_* features\")\n",
    "\n",
    "# ---- Unified size delta / ratio --------------------------------------\n",
    "unified_delta_sources = [\n",
    "    \"static_size_delta_vs_prev\",        # unified static size delta (if present)\n",
    "    \"delta_pypi_size_bytes\",           # PyPI size delta\n",
    "    \"delta_npm_unpacked_size_bytes\",   # npm unpacked size delta\n",
    "]\n",
    "\n",
    "unified_ratio_sources = [\n",
    "    \"static_size_ratio_vs_prev\",               # unified static size ratio (if present)\n",
    "    \"ratio_pypi_size_bytes\",\n",
    "    \"ratio_static_size_uncompressed_bytes\",\n",
    "    \"ratio_npm_unpacked_size_bytes\",\n",
    "]\n",
    "\n",
    "if any(src in cols for src in unified_delta_sources):\n",
    "    delta_df[\"delta_unified_size_bytes\"] = np.nan\n",
    "    for src in unified_delta_sources:\n",
    "        if src in cols:\n",
    "            delta_df[\"delta_unified_size_bytes\"] = delta_df[\n",
    "                \"delta_unified_size_bytes\"\n",
    "            ].fillna(delta_df[src])\n",
    "else:\n",
    "    delta_df[\"delta_unified_size_bytes\"] = 0.0\n",
    "\n",
    "if any(src in cols for src in unified_ratio_sources):\n",
    "    delta_df[\"ratio_unified_size\"] = np.nan\n",
    "    for src in unified_ratio_sources:\n",
    "        if src in cols:\n",
    "            delta_df[\"ratio_unified_size\"] = delta_df[\"ratio_unified_size\"].fillna(\n",
    "                delta_df[src]\n",
    "            )\n",
    "else:\n",
    "    delta_df[\"ratio_unified_size\"] = 1.0  # neutral \"no change\" ratio\n",
    "\n",
    "# ---- Density / entropy-like proxies: bytes per file-ish --------------\n",
    "\n",
    "# npm side: ratio-based \"bytes per file\" proxy\n",
    "if {\"ratio_npm_unpacked_size_bytes\", \"ratio_npm_file_count\"} <= cols:\n",
    "    denom = delta_df[\"ratio_npm_file_count\"].replace(0, np.nan)\n",
    "    delta_df[\"ratio_npm_bytes_per_file_proxy\"] = (\n",
    "        delta_df[\"ratio_npm_unpacked_size_bytes\"] / denom\n",
    "    )\n",
    "    delta_df[\"ratio_npm_bytes_per_file_proxy\"] = (\n",
    "        delta_df[\"ratio_npm_bytes_per_file_proxy\"]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(1.0)\n",
    "    )\n",
    "\n",
    "# npm side: delta-based \"bytes per file\" proxy\n",
    "if {\"delta_npm_unpacked_size_bytes\", \"delta_npm_file_count\"} <= cols:\n",
    "    denom = delta_df[\"delta_npm_file_count\"].replace(0, np.nan)\n",
    "    delta_df[\"delta_npm_bytes_per_file_proxy\"] = (\n",
    "        delta_df[\"delta_npm_unpacked_size_bytes\"] / denom\n",
    "    )\n",
    "    delta_df[\"delta_npm_bytes_per_file_proxy\"] = (\n",
    "        delta_df[\"delta_npm_bytes_per_file_proxy\"]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "\n",
    "# generic unified density proxy from static sizes + file count if available\n",
    "if {\"static_size_delta_vs_prev\", \"delta_npm_file_count\"} <= cols:\n",
    "    denom = delta_df[\"delta_npm_file_count\"].replace(0, np.nan)\n",
    "    delta_df[\"delta_unified_density_proxy\"] = (\n",
    "        delta_df[\"static_size_delta_vs_prev\"] / denom\n",
    "    )\n",
    "    delta_df[\"delta_unified_density_proxy\"] = (\n",
    "        delta_df[\"delta_unified_density_proxy\"]\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "\n",
    "density_cols = [\n",
    "    c\n",
    "    for c in [\n",
    "        \"ratio_npm_bytes_per_file_proxy\",\n",
    "        \"delta_npm_bytes_per_file_proxy\",\n",
    "        \"delta_unified_density_proxy\",\n",
    "    ]\n",
    "    if c in delta_df.columns\n",
    "]\n",
    "\n",
    "print(\"Density / entropy-like columns now present:\", density_cols)\n",
    "delta_df[density_cols].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b244f",
   "metadata": {},
   "source": [
    "## Cell 12 – Magnitude, log-magnitude, and sign of size-like deltas\n",
    "\n",
    "Here we enrich all **size-like delta features** (columns containing `size`, `unpacked`, or `bytes`) with three derived views:\n",
    "\n",
    "- **Absolute magnitude**: `{col}_abs`  \n",
    "  - Captures how big the change is in bytes, ignoring direction.\n",
    "\n",
    "- **Log-magnitude**: `{col}_log1p_abs`  \n",
    "  - Uses `log(1 + |delta|)` to reduce skew from very large jumps and make values more model-friendly.\n",
    "\n",
    "- **Direction flag**: `{col}_sign`  \n",
    "  - Encodes whether the size **decreased (-1)**, **stayed similar (0)**, or **increased (+1)**.  \n",
    "  - This separates the idea of “how big was the change?” from “did it grow or shrink?”\n",
    "\n",
    "Together, these features let the model reason about **both direction and scale** of size changes across different size-related signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ff8ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size-like delta columns: ['delta_entropy_ratio_size', 'delta_npm_unpacked_size_bytes', 'delta_pypi_size_bytes', 'static_size_delta_vs_prev']\n",
      "Example size/derived columns: ['delta_entropy_ratio_size', 'delta_entropy_ratio_size_abs', 'delta_entropy_ratio_size_log1p_abs', 'delta_entropy_ratio_size_sign', 'delta_npm_unpacked_size_bytes', 'delta_npm_unpacked_size_bytes_abs', 'delta_npm_unpacked_size_bytes_log1p_abs', 'delta_npm_unpacked_size_bytes_sign']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_entropy_ratio_size</th>\n",
       "      <th>delta_entropy_ratio_size_abs</th>\n",
       "      <th>delta_entropy_ratio_size_log1p_abs</th>\n",
       "      <th>delta_entropy_ratio_size_sign</th>\n",
       "      <th>delta_npm_unpacked_size_bytes</th>\n",
       "      <th>delta_npm_unpacked_size_bytes_abs</th>\n",
       "      <th>delta_npm_unpacked_size_bytes_log1p_abs</th>\n",
       "      <th>delta_npm_unpacked_size_bytes_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.737705</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.552565</td>\n",
       "      <td>-1</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.552565</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.737705</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.552565</td>\n",
       "      <td>-1</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.552565</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-98.451522</td>\n",
       "      <td>98.451522</td>\n",
       "      <td>4.599670</td>\n",
       "      <td>-1</td>\n",
       "      <td>-51865.0</td>\n",
       "      <td>51865.0</td>\n",
       "      <td>10.856419</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   delta_entropy_ratio_size  delta_entropy_ratio_size_abs  \\\n",
       "0                 -0.737705                      0.737705   \n",
       "1                  0.737705                      0.737705   \n",
       "2                 -0.737705                      0.737705   \n",
       "3                  0.737705                      0.737705   \n",
       "4                -98.451522                     98.451522   \n",
       "\n",
       "   delta_entropy_ratio_size_log1p_abs  delta_entropy_ratio_size_sign  \\\n",
       "0                            0.552565                             -1   \n",
       "1                            0.552565                              1   \n",
       "2                            0.552565                             -1   \n",
       "3                            0.552565                              1   \n",
       "4                            4.599670                             -1   \n",
       "\n",
       "   delta_npm_unpacked_size_bytes  delta_npm_unpacked_size_bytes_abs  \\\n",
       "0                          -45.0                               45.0   \n",
       "1                           45.0                               45.0   \n",
       "2                          -45.0                               45.0   \n",
       "3                           45.0                               45.0   \n",
       "4                       -51865.0                            51865.0   \n",
       "\n",
       "   delta_npm_unpacked_size_bytes_log1p_abs  delta_npm_unpacked_size_bytes_sign  \n",
       "0                                 3.828641                                  -1  \n",
       "1                                 3.828641                                   1  \n",
       "2                                 3.828641                                  -1  \n",
       "3                                 3.828641                                   1  \n",
       "4                                10.856419                                  -1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12 – Magnitude, log-magnitude, and sign for size-like deltas (NaN-safe)\n",
    "\n",
    "size_like_delta_cols = []\n",
    "\n",
    "for c in delta_cols + [\"static_size_delta_vs_prev\", \"delta_unified_size_bytes\"]:\n",
    "    if c in cols and (\"size\" in c or \"unpacked\" in c or \"bytes\" in c):\n",
    "        size_like_delta_cols.append(c)\n",
    "\n",
    "size_like_delta_cols = sorted(set(size_like_delta_cols))\n",
    "print(\"Size-like delta columns:\", size_like_delta_cols)\n",
    "\n",
    "for c in size_like_delta_cols:\n",
    "    # Absolute change\n",
    "    abs_col = f\"{c}_abs\"\n",
    "    delta_df[abs_col] = delta_df[c].abs()\n",
    "\n",
    "    # Log(1+|delta|) magnitude (helps strong skew)\n",
    "    log_col = f\"{c}_log1p_abs\"\n",
    "    delta_df[log_col] = np.log1p(delta_df[abs_col])\n",
    "\n",
    "    # Direction flag: -1, 0, +1\n",
    "    sign_col = f\"{c}_sign\"\n",
    "    # NaN-safe: treat missing values as 0 before taking sign\n",
    "    sign_vals = np.sign(delta_df[c].fillna(0.0))\n",
    "    delta_df[sign_col] = sign_vals.astype(\"int8\")\n",
    "\n",
    "example_cols = []\n",
    "for c in size_like_delta_cols[:2]:\n",
    "    example_cols.extend([c, f\"{c}_abs\", f\"{c}_log1p_abs\", f\"{c}_sign\"])\n",
    "\n",
    "print(\"Example size/derived columns:\", example_cols)\n",
    "delta_df[example_cols].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02793af5",
   "metadata": {},
   "source": [
    "## Cell 13 – Large-jump flags for size deltas\n",
    "\n",
    "Finally, we add **binary “large jump” flags** for each size-like delta:\n",
    "\n",
    "- For each size delta column, we compute the 95th percentile of `|delta|`.\n",
    "- We then create `{col}_large_jump` which is:\n",
    "  - `1` if `|delta|` is in the top 5% (unusually large change),\n",
    "  - `0` otherwise.\n",
    "\n",
    "These flags provide a simple, registry-inspired anomaly signal:  \n",
    "> “This version changed size much more than most other updates.”\n",
    "\n",
    "They are scale-aware (based on the observed distribution) and help the model highlight **rare, extreme size changes** that may correlate with malicious transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf5861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large-jump flag columns: ['delta_entropy_ratio_size_large_jump', 'delta_npm_unpacked_size_bytes_large_jump', 'delta_pypi_size_bytes_large_jump', 'static_size_delta_vs_prev_large_jump']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_entropy_ratio_size_large_jump</th>\n",
       "      <th>delta_npm_unpacked_size_bytes_large_jump</th>\n",
       "      <th>delta_pypi_size_bytes_large_jump</th>\n",
       "      <th>static_size_delta_vs_prev_large_jump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   delta_entropy_ratio_size_large_jump  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   delta_npm_unpacked_size_bytes_large_jump  delta_pypi_size_bytes_large_jump  \\\n",
       "0                                         0                                 0   \n",
       "1                                         0                                 0   \n",
       "2                                         0                                 0   \n",
       "3                                         0                                 0   \n",
       "4                                         0                                 0   \n",
       "\n",
       "   static_size_delta_vs_prev_large_jump  \n",
       "0                                     0  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     0  \n",
       "4                                     0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 13 – \"Large jump\" flags for size deltas (top 5% by |delta|)\n",
    "\n",
    "for c in size_like_delta_cols:\n",
    "    q = delta_df[c].abs().quantile(0.95)\n",
    "    flag_col = f\"{c}_large_jump\"\n",
    "    delta_df[flag_col] = (delta_df[c].abs() >= q).astype(\"int8\")\n",
    "\n",
    "large_jump_cols = [f\"{c}_large_jump\" for c in size_like_delta_cols]\n",
    "print(\"Large-jump flag columns:\", large_jump_cols[:10])\n",
    "delta_df[large_jump_cols].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9114ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric feature candidates (non-constant): 49\n",
      "Example feature names: ['delta_num_requires_dist', 'delta_summary_len', 'delta_description_len', 'delta_num_classifiers', 'delta_has_author', 'delta_has_license', 'delta_num_dependencies', 'delta_num_dev_dependencies', 'delta_num_scripts', 'delta_num_keywords', 'delta_version_len', 'delta_version_num_dots', 'delta_version_has_prerelease', 'static_size_prev_uncompressed_bytes', 'static_size_curr_uncompressed_bytes', 'static_size_delta_vs_prev', 'static_size_ratio_vs_prev', 'ratio_static_size_uncompressed_bytes', 'delta_pypi_size_bytes', 'ratio_pypi_size_bytes']\n",
      "X shape: (717, 49) | y shape: (717,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 – Feature matrix construction (with constant-feature removal)\n",
    "\n",
    "if \"y_malicious\" not in delta_df.columns:\n",
    "    raise ValueError(\"Expected 'y_malicious' column in delta_df\")\n",
    "\n",
    "y = delta_df[\"y_malicious\"].astype(int)\n",
    "\n",
    "exclude_cols = [\"y_malicious\"]\n",
    "exclude_cols.extend([c for c in delta_df.columns if c.startswith(\"label_\")])\n",
    "exclude_cols.extend([c for c in delta_df.columns if c.startswith(\"prev_label_\")])\n",
    "exclude_cols.extend(\n",
    "    [c for c in [\"ecosystem\", \"package_name\", \"version\", \"prev_version\"] if c in delta_df.columns]\n",
    ")\n",
    "\n",
    "# First pick numeric candidates\n",
    "numeric_candidates = [\n",
    "    c\n",
    "    for c in delta_df.columns\n",
    "    if c not in exclude_cols and delta_df[c].dtype.kind in \"biufc\"\n",
    "]\n",
    "\n",
    "# Drop constant columns (zero variance)\n",
    "nunique = delta_df[numeric_candidates].nunique(dropna=False)\n",
    "numeric_cols = nunique[nunique > 1].index.tolist()\n",
    "\n",
    "print(f\"Numeric feature candidates (non-constant): {len(numeric_cols)}\")\n",
    "print(\"Example feature names:\", numeric_cols[:20])\n",
    "\n",
    "X = delta_df[numeric_cols].fillna(0)\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c8c4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 30 features:\n",
      "  - delta_description_len\n",
      "  - delta_num_classifiers\n",
      "  - delta_num_scripts\n",
      "  - delta_num_keywords\n",
      "  - delta_version_len\n",
      "  - delta_version_num_dots\n",
      "  - delta_version_has_prerelease\n",
      "  - static_size_prev_uncompressed_bytes\n",
      "  - static_size_curr_uncompressed_bytes\n",
      "  - static_size_ratio_vs_prev\n",
      "  - ratio_static_size_uncompressed_bytes\n",
      "  - ratio_pypi_size_bytes\n",
      "  - ratio_npm_unpacked_size_bytes\n",
      "  - ratio_npm_file_count\n",
      "  - ratio_entropy_ratio_size\n",
      "  - ratio_entropy_indicator\n",
      "  - ratio_unified_size\n",
      "  - ratio_npm_bytes_per_file_proxy\n",
      "  - delta_npm_bytes_per_file_proxy\n",
      "  - delta_unified_density_proxy\n",
      "  - delta_entropy_ratio_size_log1p_abs\n",
      "  - delta_entropy_ratio_size_sign\n",
      "  - delta_npm_unpacked_size_bytes_log1p_abs\n",
      "  - delta_npm_unpacked_size_bytes_sign\n",
      "  - delta_pypi_size_bytes_abs\n",
      "  - delta_pypi_size_bytes_log1p_abs\n",
      "  - delta_pypi_size_bytes_sign\n",
      "  - static_size_delta_vs_prev_log1p_abs\n",
      "  - static_size_delta_vs_prev_sign\n",
      "  - delta_pypi_size_bytes_large_jump\n",
      "\n",
      "Saved selected features to selected_delta_features_v4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\becai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [4 5] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\becai\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Cell 15 – Feature selection via ANOVA F-test (uses X, y from Cell 14)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "if \"X\" not in globals() or \"y\" not in globals():\n",
    "    raise RuntimeError(\"Run Cell 14 first to define X and y before feature selection.\")\n",
    "\n",
    "k = min(30, X.shape[1])  # allow up to 30 features\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "selector.fit(X, y)\n",
    "\n",
    "selected_features = [numeric_cols[i] for i in selector.get_support(indices=True)]\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features:\")\n",
    "for f in selected_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "X_selected = delta_df[selected_features].fillna(0)\n",
    "\n",
    "# Save selected feature names for downstream notebooks\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "META_DIR = Path(\"../data/meta\")\n",
    "out_path = META_DIR / \"selected_delta_features_v4.csv\"\n",
    "pd.DataFrame({\"selected_feature\": selected_features}).to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved selected features to {out_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d939c576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Performance (all transitions) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.86      0.84      0.85        91\n",
      "   Malicious       0.73      0.77      0.75        53\n",
      "\n",
      "    accuracy                           0.81       144\n",
      "   macro avg       0.80      0.80      0.80       144\n",
      "weighted avg       0.82      0.81      0.81       144\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[76 15]\n",
      " [12 41]]\n",
      "\n",
      "ROC-AUC (all transitions): 0.884\n"
     ]
    }
   ],
   "source": [
    "# Cell 16 – Train/test split and Random Forest (all transitions)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "clf_all = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "clf_all.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_all.predict(X_test)\n",
    "y_proba = clf_all.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Model Performance (all transitions) ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Benign\", \"Malicious\"]))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "roc = roc_auc_score(y_test, y_proba)\n",
    "print(f\"\\nROC-AUC (all transitions): {roc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2ee86cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Feature Importances (all transitions):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>static_size_delta_vs_prev_log1p_abs</td>\n",
       "      <td>0.136944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static_size_curr_uncompressed_bytes</td>\n",
       "      <td>0.124999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static_size_prev_uncompressed_bytes</td>\n",
       "      <td>0.121882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ratio_unified_size</td>\n",
       "      <td>0.065803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static_size_ratio_vs_prev</td>\n",
       "      <td>0.058537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>delta_npm_unpacked_size_bytes_log1p_abs</td>\n",
       "      <td>0.056962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>delta_entropy_ratio_size_log1p_abs</td>\n",
       "      <td>0.049690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ratio_static_size_uncompressed_bytes</td>\n",
       "      <td>0.048484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ratio_entropy_ratio_size</td>\n",
       "      <td>0.048042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ratio_npm_bytes_per_file_proxy</td>\n",
       "      <td>0.045669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ratio_npm_unpacked_size_bytes</td>\n",
       "      <td>0.028255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>delta_version_len</td>\n",
       "      <td>0.025939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>static_size_delta_vs_prev_sign</td>\n",
       "      <td>0.023378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>delta_unified_density_proxy</td>\n",
       "      <td>0.018783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ratio_npm_file_count</td>\n",
       "      <td>0.017119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>delta_npm_bytes_per_file_proxy</td>\n",
       "      <td>0.015764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>delta_version_num_dots</td>\n",
       "      <td>0.013091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>delta_pypi_size_bytes_log1p_abs</td>\n",
       "      <td>0.012760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ratio_pypi_size_bytes</td>\n",
       "      <td>0.012415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>delta_entropy_ratio_size_sign</td>\n",
       "      <td>0.011740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    feature  importance\n",
       "0       static_size_delta_vs_prev_log1p_abs    0.136944\n",
       "1       static_size_curr_uncompressed_bytes    0.124999\n",
       "2       static_size_prev_uncompressed_bytes    0.121882\n",
       "3                        ratio_unified_size    0.065803\n",
       "4                 static_size_ratio_vs_prev    0.058537\n",
       "5   delta_npm_unpacked_size_bytes_log1p_abs    0.056962\n",
       "6        delta_entropy_ratio_size_log1p_abs    0.049690\n",
       "7      ratio_static_size_uncompressed_bytes    0.048484\n",
       "8                  ratio_entropy_ratio_size    0.048042\n",
       "9            ratio_npm_bytes_per_file_proxy    0.045669\n",
       "10            ratio_npm_unpacked_size_bytes    0.028255\n",
       "11                        delta_version_len    0.025939\n",
       "12           static_size_delta_vs_prev_sign    0.023378\n",
       "13              delta_unified_density_proxy    0.018783\n",
       "14                     ratio_npm_file_count    0.017119\n",
       "15           delta_npm_bytes_per_file_proxy    0.015764\n",
       "16                   delta_version_num_dots    0.013091\n",
       "17          delta_pypi_size_bytes_log1p_abs    0.012760\n",
       "18                    ratio_pypi_size_bytes    0.012415\n",
       "19            delta_entropy_ratio_size_sign    0.011740"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 17 – Feature importances (all transitions)\n",
    "\n",
    "feat_imp_all = (\n",
    "    pd.DataFrame(\n",
    "        {\"feature\": selected_features, \"importance\": clf_all.feature_importances_}\n",
    "    )\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nTop Feature Importances (all transitions):\")\n",
    "feat_imp_all.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e240a0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions with prev_label_malicious == 0: 0 / 717\n",
      "X_known shape: (0, 30) | y_known shape: (0,)\n",
      "Label distribution in known-good transitions:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Cell 18 – Subset to transitions where previous version is known benign\n",
    "\n",
    "if \"prev_label_malicious\" not in delta_df.columns:\n",
    "    print(\n",
    "        \"[WARN] prev_label_malicious not available; \"\n",
    "        \"transition model will reuse clf_all.\"\n",
    "    )\n",
    "    X_known = None\n",
    "    y_known = None\n",
    "else:\n",
    "    mask_prev_good = (\n",
    "        (delta_df[\"prev_label_malicious\"] == 0)\n",
    "        & delta_df[\"prev_label_malicious\"].notna()\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Transitions with prev_label_malicious == 0: \"\n",
    "        f\"{mask_prev_good.sum()} / {len(delta_df)}\"\n",
    "    )\n",
    "\n",
    "    X_known = delta_df.loc[mask_prev_good, selected_features].fillna(0)\n",
    "    y_known = delta_df.loc[mask_prev_good, \"y_malicious\"].astype(int)\n",
    "\n",
    "    print(\"X_known shape:\", X_known.shape, \"| y_known shape:\", y_known.shape)\n",
    "    print(\"Label distribution in known-good transitions:\")\n",
    "    print(y_known.value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b9dca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Not enough transitions from known-good previous versions to train a separate transition model. Using clf_all as fallback.\n"
     ]
    }
   ],
   "source": [
    "# Cell 19 – Train transition model (prev benign -> next version)\n",
    "\n",
    "clf_transition = None\n",
    "\n",
    "if X_known is None or len(X_known) < 10 or y_known.nunique() < 2:\n",
    "    print(\n",
    "        \"[WARN] Not enough transitions from known-good previous versions \"\n",
    "        \"to train a separate transition model. Using clf_all as fallback.\"\n",
    "    )\n",
    "    clf_transition = clf_all\n",
    "else:\n",
    "    Xk_train, Xk_test, yk_train, yk_test = train_test_split(\n",
    "        X_known,\n",
    "        y_known,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_known,\n",
    "    )\n",
    "\n",
    "    clf_transition = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "    )\n",
    "    clf_transition.fit(Xk_train, yk_train)\n",
    "\n",
    "    yk_pred = clf_transition.predict(Xk_test)\n",
    "    yk_proba = clf_transition.predict_proba(Xk_test)[:, 1]\n",
    "\n",
    "    print(\"\\n=== Transition Model Performance (prev benign -> next) ===\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            yk_test, yk_pred, target_names=[\"Benign\", \"Malicious\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"\\nConfusion Matrix (transition model):\")\n",
    "    print(confusion_matrix(yk_test, yk_pred))\n",
    "\n",
    "    roc_k = roc_auc_score(yk_test, yk_proba)\n",
    "    print(f\"\\nROC-AUC (transition model): {roc_k:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86629af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20 – Helper to score a specific transition from a known-good version\n",
    "\n",
    "def score_transition_from_known_good(\n",
    "    model: RandomForestClassifier,\n",
    "    df_delta: pd.DataFrame,\n",
    "    ecosystem: str,\n",
    "    package_name: str,\n",
    "    base_version: str,\n",
    "    next_version: str,\n",
    "    feature_cols: list[str],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute P(malicious) for the transition:\n",
    "        ecosystem:package_name base_version -> next_version\n",
    "\n",
    "    Uses the given model and the selected delta features.\n",
    "\n",
    "    Assumes df_delta contains:\n",
    "      - 'ecosystem', 'package_name', 'version', 'prev_version'\n",
    "      - feature_cols\n",
    "    \"\"\"\n",
    "    mask = (\n",
    "        (df_delta[ECO_COL] == ecosystem)\n",
    "        & (df_delta[PKG_COL] == package_name)\n",
    "        & (df_delta[VER_COL] == next_version)\n",
    "        & (df_delta[\"prev_version\"] == base_version)\n",
    "    )\n",
    "\n",
    "    row = df_delta.loc[mask, feature_cols]\n",
    "\n",
    "    if row.empty:\n",
    "        raise ValueError(\n",
    "            f\"No matching row for transition {ecosystem}:{package_name} \"\n",
    "            f\"{base_version} -> {next_version}\"\n",
    "        )\n",
    "\n",
    "    X_row = row.fillna(0)\n",
    "    proba = model.predict_proba(X_row)[:, 1][0]\n",
    "    return float(proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e6988ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Added synthetic demo transition row:\n",
      "    ecosystem       package_name prev_version version prev_label_malicious  \\\n",
      "717       npm  dummy-pkg-v4-demo        0.9.0   1.0.0                    0   \n",
      "\n",
      "     y_malicious  \n",
      "717            1  \n"
     ]
    }
   ],
   "source": [
    "# Cell 20b – Create synthetic dummy transition with dummy feature values\n",
    "\n",
    "# Dummy identifiers for the example transition\n",
    "demo_ecos = \"npm\"\n",
    "demo_pkg = \"dummy-pkg-v4-demo\"\n",
    "demo_prev = \"0.9.0\"   # known-good version\n",
    "demo_curr = \"1.0.0\"   # new version to evaluate\n",
    "\n",
    "# Check if this transition already exists\n",
    "mask_demo = (\n",
    "    (delta_df[ECO_COL] == demo_ecos)\n",
    "    & (delta_df[PKG_COL] == demo_pkg)\n",
    "    & (delta_df[VER_COL] == demo_curr)\n",
    "    & (delta_df[\"prev_version\"] == demo_prev)\n",
    ")\n",
    "\n",
    "if mask_demo.any():\n",
    "    print(\"[INFO] Synthetic demo transition already present in delta_df.\")\n",
    "else:\n",
    "    # Start with NaN for every column\n",
    "    fake_row = {col: np.nan for col in delta_df.columns}\n",
    "\n",
    "    # IDs\n",
    "    fake_row[ECO_COL] = demo_ecos\n",
    "    fake_row[PKG_COL] = demo_pkg\n",
    "    fake_row[VER_COL] = demo_curr\n",
    "    fake_row[\"prev_version\"] = demo_prev\n",
    "\n",
    "    # Labels: previous version benign, current version malicious (for illustration)\n",
    "    if \"prev_label_malicious\" in delta_df.columns:\n",
    "        fake_row[\"prev_label_malicious\"] = 0  # known-good base version\n",
    "    if \"y_malicious\" in delta_df.columns:\n",
    "        fake_row[\"y_malicious\"] = 1  # label for current version (dummy malicious)\n",
    "\n",
    "    # Give some dummy but \"suspicious-looking\" values for key features\n",
    "    dummy_values = {\n",
    "        # Big size jump\n",
    "        \"static_size_delta_vs_prev\": 50_000.0,\n",
    "        \"static_size_ratio_vs_prev\": 2.5,\n",
    "        \"ratio_static_size_uncompressed_bytes\": 2.5,\n",
    "        \"delta_unified_size_bytes\": 50_000.0,\n",
    "        \"ratio_unified_size\": 2.5,\n",
    "\n",
    "        # More files and larger unpacked size\n",
    "        \"delta_npm_unpacked_size_bytes\": 48_000.0,\n",
    "        \"ratio_npm_unpacked_size_bytes\": 2.4,\n",
    "        \"delta_npm_file_count\": 100.0,\n",
    "        \"ratio_npm_file_count\": 2.0,\n",
    "\n",
    "        # Entropy / density changes\n",
    "        \"delta_entropy_ratio_size\": 3_000.0,\n",
    "        \"ratio_entropy_ratio_size\": 1.6,\n",
    "        \"ratio_entropy_indicator\": 1.0,  # flipped from 0 -> 1\n",
    "\n",
    "        # Bytes-per-file proxies\n",
    "        \"ratio_npm_bytes_per_file_proxy\": 1.8,\n",
    "        \"delta_npm_bytes_per_file_proxy\": 1_000.0,\n",
    "        \"delta_unified_density_proxy\": 800.0,\n",
    "\n",
    "        # Magnitude / sign / large-jump flags (if those were created)\n",
    "        \"delta_entropy_ratio_size_abs\": 3_000.0,\n",
    "        \"delta_entropy_ratio_size_log1p_abs\": np.log1p(3_000.0),\n",
    "        \"delta_entropy_ratio_size_sign\": 1,\n",
    "        \"delta_npm_unpacked_size_bytes_abs\": 48_000.0,\n",
    "        \"delta_npm_unpacked_size_bytes_log1p_abs\": np.log1p(48_000.0),\n",
    "        \"delta_npm_unpacked_size_bytes_sign\": 1,\n",
    "        \"delta_entropy_ratio_size_large_jump\": 1,\n",
    "        \"delta_npm_unpacked_size_bytes_large_jump\": 1,\n",
    "        \"static_size_delta_vs_prev_large_jump\": 1,\n",
    "    }\n",
    "\n",
    "    # Fill selected features with dummy values where possible, fallback to 0.0\n",
    "    for f in selected_features:\n",
    "        if f in fake_row:  # column exists in delta_df\n",
    "            if f in dummy_values:\n",
    "                fake_row[f] = dummy_values[f]\n",
    "            else:\n",
    "                fake_row[f] = 0.0  # neutral dummy value\n",
    "\n",
    "    # Append to delta_df\n",
    "    delta_df = pd.concat([delta_df, pd.DataFrame([fake_row])], ignore_index=True)\n",
    "    print(\"[INFO] Added synthetic demo transition row:\")\n",
    "    print(\n",
    "        delta_df.tail(1)[\n",
    "            [ECO_COL, PKG_COL, \"prev_version\", VER_COL, \"prev_label_malicious\", \"y_malicious\"]\n",
    "            if \"prev_label_malicious\" in delta_df.columns\n",
    "            else [ECO_COL, PKG_COL, \"prev_version\", VER_COL, \"y_malicious\"]\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eda75dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(malicious) for transition npm:dummy-pkg-v4-demo 0.9.0 -> 1.0.0: 0.295\n"
     ]
    }
   ],
   "source": [
    "# Cell 21 – Example: scoring the synthetic dummy transition\n",
    "\n",
    "demo_ecos = \"npm\"\n",
    "demo_pkg = \"dummy-pkg-v4-demo\"\n",
    "demo_prev = \"0.9.0\"\n",
    "demo_curr = \"1.0.0\"\n",
    "\n",
    "p_mal = score_transition_from_known_good(\n",
    "    model=clf_transition,\n",
    "    df_delta=delta_df,\n",
    "    ecosystem=demo_ecos,\n",
    "    package_name=demo_pkg,\n",
    "    base_version=demo_prev,\n",
    "    next_version=demo_curr,\n",
    "    feature_cols=selected_features,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"P(malicious) for transition {demo_ecos}:{demo_pkg} \"\n",
    "    f\"{demo_prev} -> {demo_curr}: {p_mal:.3f}\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbfb7a7",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Live-Registry Metadata Version-Diff Model (PyPI + npm, no registry_df)\n",
    "\n",
    "Goal: compare metadata between **benign vs malicious versions of the same package**,\n",
    "using *live* metadata from PyPI and npm.\n",
    "\n",
    "Inputs:\n",
    "- data/meta/labels_version.csv  (one row per malicious version: ecosystem, package_name, version, is_malicious_any_version)\n",
    "- data/meta/labels_package.csv  (one row per malicious package)\n",
    "\n",
    "Outputs:\n",
    "- data/meta/version_delta_features_live.csv\n",
    "  Each row is a pair (prev_version → malicious_version) with delta metadata features and label y=1 (malicious).\n",
    "  Optional: we also add a few benign→benign pairs (y=0) as negative examples.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5173bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META_DIR: C:\\Users\\becai\\Desktop\\CSI 4900 Jupyter\\Jupyter_v2\\data\\meta\n",
      "labels_version: C:\\Users\\becai\\Desktop\\CSI 4900 Jupyter\\Jupyter_v2\\data\\meta\\labels_version_v1.csv\n",
      "labels_package: C:\\Users\\becai\\Desktop\\CSI 4900 Jupyter\\Jupyter_v2\\data\\meta\\labels_package_v1.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 – Imports & basic config\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "import requests\n",
    "from packaging import version as py_version\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "META_DIR = Path(\"../data/meta\")\n",
    "LABELS_VERSION_PATH = META_DIR / \"labels_version_v1.csv\"\n",
    "LABELS_PACKAGE_PATH = META_DIR / \"labels_package_v1.csv\"\n",
    "\n",
    "print(\"META_DIR:\", META_DIR.resolve())\n",
    "print(\"labels_version:\", LABELS_VERSION_PATH.resolve())\n",
    "print(\"labels_package:\", LABELS_PACKAGE_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b33f309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_version shape: (33773, 10)\n",
      "labels_package shape: (20676, 8)\n",
      "labels_version_live shape (pypi + npm): (33773, 10)\n",
      "By ecosystem:\n",
      "ecosystem\n",
      "npm     27297\n",
      "pypi     6476\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecosystem</th>\n",
       "      <th>package_name</th>\n",
       "      <th>version</th>\n",
       "      <th>is_malicious_datadog</th>\n",
       "      <th>is_malicious_osv</th>\n",
       "      <th>osv_id</th>\n",
       "      <th>osv_published</th>\n",
       "      <th>osv_modified</th>\n",
       "      <th>osv_summary</th>\n",
       "      <th>is_malicious_any_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>npm</td>\n",
       "      <td>-accion-pelicula-john-wick-4-keanu-reeves-peli...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MAL-2024-1677</td>\n",
       "      <td>2024-06-25T12:23:49Z</td>\n",
       "      <td>2024-06-25T12:23:49Z</td>\n",
       "      <td>Malicious code in -accion-pelicula-john-wick-4...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>npm</td>\n",
       "      <td>-accion-pelicula-john-wick-4-keanu-reeves-peli...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MAL-2024-1678</td>\n",
       "      <td>2024-06-25T12:23:50Z</td>\n",
       "      <td>2024-06-25T12:23:50Z</td>\n",
       "      <td>Malicious code in -accion-pelicula-john-wick-4...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>npm</td>\n",
       "      <td>-espanol-john-wick-keanu-4-k-varindo-en-casa-e...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MAL-2024-1679</td>\n",
       "      <td>2024-06-25T12:23:50Z</td>\n",
       "      <td>2024-06-25T12:23:50Z</td>\n",
       "      <td>Malicious code in -espanol-john-wick-keanu-4-k...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>npm</td>\n",
       "      <td>-espanol-john-wick-keanu-reeves-4-k-varindo-en...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MAL-2024-1680</td>\n",
       "      <td>2024-06-25T12:23:51Z</td>\n",
       "      <td>2024-06-25T12:23:51Z</td>\n",
       "      <td>Malicious code in -espanol-john-wick-keanu-ree...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>npm</td>\n",
       "      <td>-john-wick-4-keanu-reeves-pelicula-completa-4-...</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>MAL-2024-1681</td>\n",
       "      <td>2024-06-25T12:23:52Z</td>\n",
       "      <td>2024-06-25T12:23:52Z</td>\n",
       "      <td>Malicious code in -john-wick-4-keanu-reeves-pe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ecosystem                                       package_name version  \\\n",
       "0       npm  -accion-pelicula-john-wick-4-keanu-reeves-peli...   1.0.0   \n",
       "1       npm  -accion-pelicula-john-wick-4-keanu-reeves-peli...   1.0.0   \n",
       "2       npm  -espanol-john-wick-keanu-4-k-varindo-en-casa-e...   1.0.0   \n",
       "3       npm  -espanol-john-wick-keanu-reeves-4-k-varindo-en...   1.0.0   \n",
       "4       npm  -john-wick-4-keanu-reeves-pelicula-completa-4-...   1.0.0   \n",
       "\n",
       "   is_malicious_datadog  is_malicious_osv         osv_id  \\\n",
       "0                 False              True  MAL-2024-1677   \n",
       "1                 False              True  MAL-2024-1678   \n",
       "2                 False              True  MAL-2024-1679   \n",
       "3                 False              True  MAL-2024-1680   \n",
       "4                 False              True  MAL-2024-1681   \n",
       "\n",
       "          osv_published          osv_modified  \\\n",
       "0  2024-06-25T12:23:49Z  2024-06-25T12:23:49Z   \n",
       "1  2024-06-25T12:23:50Z  2024-06-25T12:23:50Z   \n",
       "2  2024-06-25T12:23:50Z  2024-06-25T12:23:50Z   \n",
       "3  2024-06-25T12:23:51Z  2024-06-25T12:23:51Z   \n",
       "4  2024-06-25T12:23:52Z  2024-06-25T12:23:52Z   \n",
       "\n",
       "                                         osv_summary  is_malicious_any_version  \n",
       "0  Malicious code in -accion-pelicula-john-wick-4...                      True  \n",
       "1  Malicious code in -accion-pelicula-john-wick-4...                      True  \n",
       "2  Malicious code in -espanol-john-wick-keanu-4-k...                      True  \n",
       "3  Malicious code in -espanol-john-wick-keanu-ree...                      True  \n",
       "4  Malicious code in -john-wick-4-keanu-reeves-pe...                      True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 – Load labels and filter to ecosystems we can hit live (PyPI + npm)\n",
    "\n",
    "labels_version = pd.read_csv(LABELS_VERSION_PATH)\n",
    "labels_package = pd.read_csv(LABELS_PACKAGE_PATH)\n",
    "\n",
    "print(\"labels_version shape:\", labels_version.shape)\n",
    "print(\"labels_package shape:\", labels_package.shape)\n",
    "\n",
    "# We only handle these two for now\n",
    "supported_ecosystems = {\"pypi\", \"npm\"}\n",
    "labels_version_live = labels_version[labels_version[\"ecosystem\"].isin(supported_ecosystems)].copy()\n",
    "\n",
    "print(\"labels_version_live shape (pypi + npm):\", labels_version_live.shape)\n",
    "print(\"By ecosystem:\")\n",
    "print(labels_version_live[\"ecosystem\"].value_counts())\n",
    "labels_version_live.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3f817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 – Helper functions for PyPI metadata\n",
    "\n",
    "PYPI_BASE = \"https://pypi.org/pypi\"\n",
    "\n",
    "def fetch_pypi_project(pkg):\n",
    "    \"\"\"\n",
    "    Fetch project-wide info: list of all versions plus metadata dict.\n",
    "    \"\"\"\n",
    "    url = f\"{PYPI_BASE}/{pkg}/json\"\n",
    "    r = requests.get(url, timeout=10)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    return r.json()\n",
    "\n",
    "def fetch_pypi_version_metadata(pkg, ver):\n",
    "    \"\"\"\n",
    "    Fetch per-version PyPI metadata for (pkg, ver).\n",
    "\n",
    "    Returns a dict of numeric features, or None on failure.\n",
    "    \"\"\"\n",
    "    url = f\"{PYPI_BASE}/{pkg}/{ver}/json\"\n",
    "    r = requests.get(url, timeout=10)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    data = r.json()\n",
    "    info = data.get(\"info\") or {}\n",
    "\n",
    "    requires_dist = info.get(\"requires_dist\") or []\n",
    "    summary = info.get(\"summary\") or \"\"\n",
    "    description = info.get(\"description\") or \"\"\n",
    "    author = info.get(\"author\") or \"\"\n",
    "    license_str = info.get(\"license\") or \"\"\n",
    "    classifiers = info.get(\"classifiers\") or []\n",
    "\n",
    "    # Some simple numeric / indicator features\n",
    "    return {\n",
    "        \"num_requires_dist\": len(requires_dist),\n",
    "        \"summary_len\": len(summary),\n",
    "        \"description_len\": len(description),\n",
    "        \"num_classifiers\": len(classifiers),\n",
    "        \"has_author\": int(bool(author.strip())),\n",
    "        \"has_license\": int(bool(license_str.strip())),\n",
    "    }\n",
    "\n",
    "def find_prev_pypi_version(project_data, target_ver_str):\n",
    "    \"\"\"\n",
    "    Given project_data from fetch_pypi_project, find the highest version < target_ver_str.\n",
    "    Uses packaging.version for ordering.\n",
    "    \"\"\"\n",
    "    releases = project_data.get(\"releases\") or {}\n",
    "    all_versions = list(releases.keys())\n",
    "    if not all_versions:\n",
    "        return None\n",
    "\n",
    "    parsed_versions = []\n",
    "    for v in all_versions:\n",
    "        try:\n",
    "            parsed_versions.append((py_version.parse(v), v))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    parsed_versions.sort()\n",
    "    target = py_version.parse(target_ver_str)\n",
    "\n",
    "    prev = None\n",
    "    for v_parsed, v_str in parsed_versions:\n",
    "        if v_parsed < target:\n",
    "            prev = v_str\n",
    "        elif v_parsed == target:\n",
    "            break\n",
    "    return prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358ed0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 – Helper functions for npm metadata\n",
    "\n",
    "NPM_BASE = \"https://registry.npmjs.org\"\n",
    "\n",
    "def npm_name_to_url(pkg):\n",
    "    \"\"\"\n",
    "    Handle scoped packages like '@scope/name' -> '@scope%2fname'.\n",
    "    \"\"\"\n",
    "    if pkg.startswith(\"@\") and \"/\" in pkg:\n",
    "        scope, name = pkg.split(\"/\", 1)\n",
    "        return f\"{scope}%2f{name}\"\n",
    "    return pkg\n",
    "\n",
    "def fetch_npm_project(pkg):\n",
    "    \"\"\"\n",
    "    Fetch npm project-wide info: all versions & per-version metadata.\n",
    "    \"\"\"\n",
    "    pkg_for_url = npm_name_to_url(pkg)\n",
    "    url = f\"{NPM_BASE}/{pkg_for_url}\"\n",
    "    r = requests.get(url, timeout=10)\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    return r.json()\n",
    "\n",
    "def extract_npm_version_metadata(vdata):\n",
    "    \"\"\"\n",
    "    vdata is the per-version JSON object from npm's \"versions\" dict.\n",
    "    Returns numeric metafeatures or None.\n",
    "    \"\"\"\n",
    "    if vdata is None:\n",
    "        return None\n",
    "\n",
    "    deps = vdata.get(\"dependencies\") or {}\n",
    "    dev_deps = vdata.get(\"devDependencies\") or {}\n",
    "    scripts = vdata.get(\"scripts\") or {}\n",
    "    description = vdata.get(\"description\") or \"\"\n",
    "    keywords = vdata.get(\"keywords\") or []\n",
    "\n",
    "    return {\n",
    "        \"num_dependencies\": len(deps),\n",
    "        \"num_dev_dependencies\": len(dev_deps),\n",
    "        \"num_scripts\": len(scripts),\n",
    "        \"description_len\": len(description),\n",
    "        \"num_keywords\": len(keywords),\n",
    "    }\n",
    "\n",
    "def find_prev_npm_version(project_data, target_ver_str):\n",
    "    \"\"\"\n",
    "    Given project_data from fetch_npm_project, find the lexicographically\n",
    "    previous version. For rigorous semver ordering you'd use a semver parser,\n",
    "    but sorted() is a reasonable approximation for many packages.\n",
    "    \"\"\"\n",
    "    versions = project_data.get(\"versions\") or {}\n",
    "    if not versions:\n",
    "        return None\n",
    "\n",
    "    all_versions = sorted(versions.keys())\n",
    "    prev = None\n",
    "    for v in all_versions:\n",
    "        if v < target_ver_str:\n",
    "            prev = v\n",
    "        elif v == target_ver_str:\n",
    "            break\n",
    "    return prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a59102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 – Build live metadata for malicious + previous benign versions (improved)\n",
    "\n",
    "N_PREV_BENIGN = 3  # how many previous benign versions to try per malicious one\n",
    "\n",
    "records = []\n",
    "\n",
    "# Stats to understand why labels are dropped\n",
    "stats = {\n",
    "    \"total_labels\": 0,\n",
    "    \"unsupported_eco\": 0,\n",
    "    \"project_fetch_fail\": 0,\n",
    "    \"version_not_found\": 0,\n",
    "    \"version_matched_raw\": 0,\n",
    "    \"version_matched_normalized\": 0,\n",
    "    \"meta_fail\": 0,\n",
    "    \"added_malicious\": 0,\n",
    "    \"no_prev_candidates\": 0,\n",
    "    \"prev_is_malicious\": 0,\n",
    "    \"prev_meta_fail\": 0,\n",
    "    \"added_prev_benign\": 0,\n",
    "}\n",
    "\n",
    "# Work on unique malicious (eco, pkg, ver) for supported ecosystems only\n",
    "supported_ecosystems = {\"pypi\", \"npm\"}\n",
    "mal_rows = labels_version[\n",
    "    labels_version[\"ecosystem\"].isin(supported_ecosystems)\n",
    "].drop_duplicates(subset=[\"ecosystem\", \"package_name\", \"version\"])\n",
    "\n",
    "# Precompute set of all malicious keys for quick lookup\n",
    "malicious_version_keys = set(\n",
    "    (str(r[\"ecosystem\"]), str(r[\"package_name\"]), str(r[\"version\"]))\n",
    "    for _, r in mal_rows.iterrows()\n",
    ")\n",
    "\n",
    "# Caches so we don't refetch the same project multiple times\n",
    "pypi_project_cache = {}\n",
    "npm_project_cache = {}\n",
    "\n",
    "def is_labeled_malicious(eco, pkg, ver_str):\n",
    "    return (eco, pkg, str(ver_str)) in malicious_version_keys\n",
    "\n",
    "for idx, row in mal_rows.iterrows():\n",
    "    stats[\"total_labels\"] += 1\n",
    "    eco = row[\"ecosystem\"]\n",
    "    pkg = row[\"package_name\"]\n",
    "    ver_label = str(row[\"version\"])\n",
    "\n",
    "    if eco not in supported_ecosystems:\n",
    "        stats[\"unsupported_eco\"] += 1\n",
    "        continue\n",
    "\n",
    "    # --------------------------- PyPI branch ---------------------------\n",
    "    if eco == \"pypi\":\n",
    "        # Fetch project-level info once per package\n",
    "        if pkg not in pypi_project_cache:\n",
    "            proj_data = fetch_pypi_project(pkg)\n",
    "            pypi_project_cache[pkg] = proj_data\n",
    "            time.sleep(0.1)\n",
    "        else:\n",
    "            proj_data = pypi_project_cache[pkg]\n",
    "\n",
    "        if proj_data is None:\n",
    "            stats[\"project_fetch_fail\"] += 1\n",
    "            continue\n",
    "\n",
    "        releases = proj_data.get(\"releases\") or {}\n",
    "        if not releases:\n",
    "            stats[\"version_not_found\"] += 1\n",
    "            continue\n",
    "\n",
    "        # Version normalization: try several candidate strings\n",
    "        candidates = {ver_label}\n",
    "        if ver_label.startswith(\"v\"):\n",
    "            candidates.add(ver_label[1:])\n",
    "        if \"_\" in ver_label:\n",
    "            candidates.add(ver_label.replace(\"_\", \".\"))\n",
    "\n",
    "        matched_ver = None\n",
    "        matched_normalized = False\n",
    "\n",
    "        # First try direct / normalized matches\n",
    "        for cand in candidates:\n",
    "            if cand in releases:\n",
    "                matched_ver = cand\n",
    "                matched_normalized = (cand != ver_label)\n",
    "                break\n",
    "\n",
    "        # If still nothing, give up on this label\n",
    "        if matched_ver is None:\n",
    "            stats[\"version_not_found\"] += 1\n",
    "            continue\n",
    "\n",
    "        if matched_normalized:\n",
    "            stats[\"version_matched_normalized\"] += 1\n",
    "        else:\n",
    "            stats[\"version_matched_raw\"] += 1\n",
    "\n",
    "        # Fetch malicious version metadata\n",
    "        cur_meta = fetch_pypi_version_metadata(pkg, matched_ver)\n",
    "        time.sleep(0.1)\n",
    "        if cur_meta is None:\n",
    "            stats[\"meta_fail\"] += 1\n",
    "            continue\n",
    "\n",
    "        rec_cur = {\n",
    "            \"ecosystem\": eco,\n",
    "            \"package_name\": pkg,\n",
    "            \"version\": matched_ver,\n",
    "            \"label_malicious\": 1,\n",
    "        }\n",
    "        rec_cur.update(cur_meta)\n",
    "        records.append(rec_cur)\n",
    "        stats[\"added_malicious\"] += 1\n",
    "\n",
    "        # Find up to N_PREV_BENIGN previous benign versions\n",
    "        all_versions = []\n",
    "        for v_str in releases.keys():\n",
    "            try:\n",
    "                all_versions.append((py_version.parse(v_str), v_str))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not all_versions:\n",
    "            stats[\"no_prev_candidates\"] += 1\n",
    "            continue\n",
    "\n",
    "        all_versions.sort()\n",
    "        target_parsed = py_version.parse(matched_ver)\n",
    "        prev_candidates = []\n",
    "\n",
    "        # Walk backwards from versions < target\n",
    "        for v_parsed, v_str in reversed(all_versions):\n",
    "            if v_parsed >= target_parsed:\n",
    "                continue\n",
    "            if is_labeled_malicious(eco, pkg, v_str):\n",
    "                stats[\"prev_is_malicious\"] += 1\n",
    "                continue\n",
    "            prev_candidates.append(v_str)\n",
    "            if len(prev_candidates) >= N_PREV_BENIGN:\n",
    "                break\n",
    "\n",
    "        if not prev_candidates:\n",
    "            stats[\"no_prev_candidates\"] += 1\n",
    "        else:\n",
    "            for prev_ver in prev_candidates:\n",
    "                prev_meta = fetch_pypi_version_metadata(pkg, prev_ver)\n",
    "                time.sleep(0.1)\n",
    "                if prev_meta is None:\n",
    "                    stats[\"prev_meta_fail\"] += 1\n",
    "                    continue\n",
    "                rec_prev = {\n",
    "                    \"ecosystem\": eco,\n",
    "                    \"package_name\": pkg,\n",
    "                    \"version\": str(prev_ver),\n",
    "                    \"label_malicious\": 0,\n",
    "                }\n",
    "                rec_prev.update(prev_meta)\n",
    "                records.append(rec_prev)\n",
    "                stats[\"added_prev_benign\"] += 1\n",
    "\n",
    "    # --------------------------- npm branch ---------------------------\n",
    "    elif eco == \"npm\":\n",
    "        if pkg not in npm_project_cache:\n",
    "            proj_data = fetch_npm_project(pkg)\n",
    "            npm_project_cache[pkg] = proj_data\n",
    "            time.sleep(0.1)\n",
    "        else:\n",
    "            proj_data = npm_project_cache[pkg]\n",
    "\n",
    "        if proj_data is None:\n",
    "            stats[\"project_fetch_fail\"] += 1\n",
    "            continue\n",
    "\n",
    "        versions_dict = proj_data.get(\"versions\") or {}\n",
    "        if not versions_dict:\n",
    "            stats[\"version_not_found\"] += 1\n",
    "            continue\n",
    "\n",
    "        # Version normalization / candidate search\n",
    "        candidates = {ver_label}\n",
    "        if ver_label.startswith(\"v\"):\n",
    "            candidates.add(ver_label[1:])\n",
    "\n",
    "        matched_ver = None\n",
    "        matched_normalized = False\n",
    "\n",
    "        # Exact/normalized matches\n",
    "        for cand in candidates:\n",
    "            if cand in versions_dict:\n",
    "                matched_ver = cand\n",
    "                matched_normalized = (cand != ver_label)\n",
    "                break\n",
    "\n",
    "        # Fallback: try prefix match (e.g., \"1.0.0-beta\" vs \"1.0.0-beta.0\")\n",
    "        if matched_ver is None:\n",
    "            pref_matches = [v for v in versions_dict.keys() if v.startswith(ver_label)]\n",
    "            if pref_matches:\n",
    "                matched_ver = sorted(pref_matches)[0]\n",
    "                matched_normalized = True\n",
    "\n",
    "        if matched_ver is None:\n",
    "            stats[\"version_not_found\"] += 1\n",
    "            continue\n",
    "\n",
    "        if matched_normalized:\n",
    "            stats[\"version_matched_normalized\"] += 1\n",
    "        else:\n",
    "            stats[\"version_matched_raw\"] += 1\n",
    "\n",
    "        cur_meta = extract_npm_version_metadata(versions_dict.get(matched_ver))\n",
    "        if cur_meta is None:\n",
    "            stats[\"meta_fail\"] += 1\n",
    "            continue\n",
    "\n",
    "        rec_cur = {\n",
    "            \"ecosystem\": eco,\n",
    "            \"package_name\": pkg,\n",
    "            \"version\": matched_ver,\n",
    "            \"label_malicious\": 1,\n",
    "        }\n",
    "        rec_cur.update(cur_meta)\n",
    "        records.append(rec_cur)\n",
    "        stats[\"added_malicious\"] += 1\n",
    "\n",
    "        # Find up to N_PREV_BENIGN previous benign versions (lexicographic order)\n",
    "        all_versions = sorted(versions_dict.keys())\n",
    "        try:\n",
    "            target_idx = all_versions.index(matched_ver)\n",
    "        except ValueError:\n",
    "            stats[\"no_prev_candidates\"] += 1\n",
    "            continue\n",
    "\n",
    "        prev_candidates = []\n",
    "        for v_str in reversed(all_versions[:target_idx]):\n",
    "            if is_labeled_malicious(eco, pkg, v_str):\n",
    "                stats[\"prev_is_malicious\"] += 1\n",
    "                continue\n",
    "            prev_candidates.append(v_str)\n",
    "            if len(prev_candidates) >= N_PREV_BENIGN:\n",
    "                break\n",
    "\n",
    "        if not prev_candidates:\n",
    "            stats[\"no_prev_candidates\"] += 1\n",
    "        else:\n",
    "            for prev_ver in prev_candidates:\n",
    "                prev_meta = extract_npm_version_metadata(versions_dict.get(prev_ver))\n",
    "                if prev_meta is None:\n",
    "                    stats[\"prev_meta_fail\"] += 1\n",
    "                    continue\n",
    "                rec_prev = {\n",
    "                    \"ecosystem\": eco,\n",
    "                    \"package_name\": pkg,\n",
    "                    \"version\": str(prev_ver),\n",
    "                    \"label_malicious\": 0,\n",
    "                }\n",
    "                rec_prev.update(prev_meta)\n",
    "                records.append(rec_prev)\n",
    "                stats[\"added_prev_benign\"] += 1\n",
    "\n",
    "print(\"Stats:\", stats)\n",
    "print(\"Total rows collected (malicious + prev-benign):\", len(records))\n",
    "\n",
    "live_meta_df = pd.DataFrame(records)\n",
    "print(\"live_meta_df shape:\", live_meta_df.shape)\n",
    "print(\"label_malicious counts:\")\n",
    "print(live_meta_df[\"label_malicious\"].value_counts(dropna=False))\n",
    "\n",
    "live_meta_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell A – Normalize features and add version-string features\n",
    "\n",
    "df = live_meta_df.copy()\n",
    "\n",
    "# Common feature names across ecosystems – some may be all zeros for one eco\n",
    "all_feature_cols = [\n",
    "    \"num_requires_dist\",\n",
    "    \"summary_len\",\n",
    "    \"description_len\",\n",
    "    \"num_classifiers\",\n",
    "    \"has_author\",\n",
    "    \"has_license\",\n",
    "    \"num_dependencies\",\n",
    "    \"num_dev_dependencies\",\n",
    "    \"num_scripts\",\n",
    "    \"num_keywords\",\n",
    "]\n",
    "\n",
    "# Ensure all these columns exist (fill missing with 0)\n",
    "for col in all_feature_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n",
    "\n",
    "# Version string features\n",
    "vstr = df[\"version\"].astype(str)\n",
    "df[\"version_len\"] = vstr.str.len()\n",
    "df[\"version_num_dots\"] = vstr.str.count(r\"\\.\")\n",
    "df[\"version_has_prerelease\"] = vstr.str.contains(r\"[A-Za-z-]\", regex=True).astype(int)\n",
    "\n",
    "# Final list of feature columns\n",
    "feature_cols = all_feature_cols + [\n",
    "    \"version_len\",\n",
    "    \"version_num_dots\",\n",
    "    \"version_has_prerelease\",\n",
    "]\n",
    "\n",
    "print(\"Final feature columns:\", feature_cols)\n",
    "df[[\"ecosystem\", \"package_name\", \"version\", \"label_malicious\"] + feature_cols].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b37f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 – Build per-version diff dataset from live metadata\n",
    "\n",
    "# Sort within each package by version string (approximation)\n",
    "df_sorted = (\n",
    "    df.sort_values([\"ecosystem\", \"package_name\", \"version\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "group_key = [\"ecosystem\", \"package_name\"]\n",
    "\n",
    "# Shift features and labels within each package\n",
    "df_sorted[\"prev_version\"] = df_sorted.groupby(group_key)[\"version\"].shift(1)\n",
    "df_sorted[\"prev_label_malicious\"] = df_sorted.groupby(group_key)[\"label_malicious\"].shift(1)\n",
    "\n",
    "for col in feature_cols:\n",
    "    df_sorted[f\"prev_{col}\"] = df_sorted.groupby(group_key)[col].shift(1)\n",
    "\n",
    "diff_rows = df_sorted[df_sorted[\"prev_version\"].notna()].copy()\n",
    "\n",
    "delta_cols = []\n",
    "for col in feature_cols:\n",
    "    dcol = f\"delta_{col}\"\n",
    "    diff_rows[dcol] = diff_rows[col] - diff_rows[f\"prev_{col}\"]\n",
    "    delta_cols.append(dcol)\n",
    "\n",
    "# Label is \"is the current version malicious?\"\n",
    "diff_rows[\"y_malicious\"] = diff_rows[\"label_malicious\"].astype(int)\n",
    "\n",
    "print(\"diff_rows shape:\", diff_rows.shape)\n",
    "print(\"y_malicious value_counts:\")\n",
    "print(diff_rows[\"y_malicious\"].value_counts(dropna=False))\n",
    "\n",
    "cols_to_show = (\n",
    "    group_key\n",
    "    + [\"prev_version\", \"version\", \"prev_label_malicious\", \"label_malicious\", \"y_malicious\"]\n",
    "    + delta_cols[:5]\n",
    ")\n",
    "diff_rows[cols_to_show].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 – Save live delta dataset\n",
    "\n",
    "DELTA_LIVE_PATH = META_DIR / \"version_delta_features_live.csv\"\n",
    "\n",
    "save_cols = (\n",
    "    [\"ecosystem\", \"package_name\", \"prev_version\", \"version\", \"y_malicious\"]\n",
    "    + delta_cols\n",
    ")\n",
    "\n",
    "delta_live = diff_rows[save_cols].copy()\n",
    "delta_live.to_csv(DELTA_LIVE_PATH, index=False)\n",
    "\n",
    "print(\"Saved live-registry delta features to:\", DELTA_LIVE_PATH)\n",
    "print(\"delta_live shape:\", delta_live.shape)\n",
    "print(\"Class counts in y_malicious (0=benign, 1=malicious):\")\n",
    "print(delta_live[\"y_malicious\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d57b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 – Simple classifier on live delta features\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "X = delta_live[delta_cols].fillna(0.0).astype(float)\n",
    "y = delta_live[\"y_malicious\"].astype(int)\n",
    "\n",
    "print(\"Class counts (0=benign, 1=malicious):\")\n",
    "print(y.value_counts(dropna=False))\n",
    "\n",
    "if y.nunique() < 2:\n",
    "    print(\n",
    "        \"\\nNot enough class diversity yet. If you only see 1s or 0s, \"\n",
    "        \"either the registry didn't have prev versions for your malicious ones, \"\n",
    "        \"or many fetches failed. Try:\\n\"\n",
    "        \"  - Expanding to more packages (remove any sample() limit),\\n\"\n",
    "        \"  - Handling more ecosystems,\\n\"\n",
    "        \"  - Or adding some purely benign version pairs per package.\"\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"\\n=== Classification report (live delta model) ===\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a73d41-851c-4a06-a667-fdbfcecb160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell G1 – Label balance and coverage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Label balance in live_meta_df (per-version metadata)\n",
    "label_counts = live_meta_df[\"label_malicious\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "label_counts.plot(kind=\"bar\")\n",
    "plt.xticks([0, 1], [\"benign (0)\", \"malicious (1)\"], rotation=0)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Per-version labels in live_meta_df\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Label balance in delta_live (benign→* transitions)\n",
    "if \"delta_live\" in globals():\n",
    "    y_counts = delta_live[\"y_malicious\"].value_counts().sort_index()\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    y_counts.plot(kind=\"bar\")\n",
    "    plt.xticks([0, 1], [\"stay benign (0)\", \"turned malicious (1)\"], rotation=0)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Transition labels in delta_live\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"delta_live not found – run the delta-building cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be537b9a",
   "metadata": {},
   "source": [
    "### Cell G1 – Label balance and coverage\n",
    "\n",
    "These bar charts are a quick sanity check on how much labeled data we actually have and how imbalanced it is.\n",
    "\n",
    "- The **first bar chart** shows the label balance in `live_meta_df`: how many package *versions* are tagged as benign vs malicious. We only have 84 versions total, with roughly three times as many benign as malicious (63 benign vs 21 malicious).  \n",
    "  - This confirms the dataset is small and slightly imbalanced, so any model trained on it should be treated as exploratory rather than production-grade.\n",
    "- The **second bar chart** shows the label balance in `delta_live` (`y_malicious`): how many **benign→benign** vs **benign→malicious** transitions we found when aligning a malicious version with its previous benign version. There are more “stay benign” transitions than “turn malicious” ones.\n",
    "  - This tells us that even in the “delta” view we still have class imbalance, but both classes are represented in reasonable numbers.\n",
    "\n",
    "Overall, G1 answers: **Do we have enough positive and negative examples to run supervised experiments at all, and how imbalanced are they?** The answer is “barely yes, with noticeable but not extreme imbalance.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell G2 – Static metadata feature distributions by label\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick a few interesting features (only those actually present)\n",
    "candidate_features = [\n",
    "    \"num_requires_dist\",\n",
    "    \"num_dependencies\",\n",
    "    \"num_dev_dependencies\",\n",
    "    \"summary_len\",\n",
    "    \"description_len\",\n",
    "    \"num_scripts\",\n",
    "]\n",
    "plot_features = [f for f in candidate_features if f in live_meta_df.columns]\n",
    "\n",
    "print(\"Plotting feature distributions for:\", plot_features)\n",
    "\n",
    "for feat in plot_features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Benign\n",
    "    benign_vals = live_meta_df[live_meta_df[\"label_malicious\"] == 0][feat].dropna()\n",
    "    # Malicious\n",
    "    mal_vals = live_meta_df[live_meta_df[\"label_malicious\"] == 1][feat].dropna()\n",
    "\n",
    "    # Choose shared bins\n",
    "    all_vals = pd.concat([benign_vals, mal_vals])\n",
    "    if all_vals.empty:\n",
    "        print(f\"Skipping {feat}: no data.\")\n",
    "        plt.close()\n",
    "        continue\n",
    "\n",
    "    bins = np.histogram_bin_edges(all_vals, bins=15)\n",
    "\n",
    "    plt.hist(benign_vals, bins=bins, alpha=0.5, label=\"benign\")\n",
    "    plt.hist(mal_vals, bins=bins, alpha=0.5, label=\"malicious\")\n",
    "\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"{feat}: benign vs malicious (live_meta_df)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc3075",
   "metadata": {},
   "source": [
    "### Cell G2 – Static metadata feature distributions by label\n",
    "\n",
    "These plots compare **simple registry metadata features** between benign and malicious versions in `live_meta_df`.\n",
    "\n",
    "- For each feature (e.g. `num_dependencies`, `num_dev_dependencies`, `description_len`, `num_scripts`), we plot the **benign** and **malicious** distributions on the same axis (often with a log-scaled x-axis).\n",
    "- The goal is to eyeball whether malicious versions systematically differ in obvious ways:\n",
    "  - Do malicious versions tend to have **more or fewer dependencies**?\n",
    "  - Are their **descriptions shorter or longer**?\n",
    "  - Are they more likely to define **scripts**?\n",
    "- Heavy overlap between the curves means “this feature alone is weak as a detector,” while clearly shifted or skewed distributions hint at features that might carry some signal once combined in a model.\n",
    "\n",
    "In short, G2 provides a **univariate** view of the static metadata and helps decide which features are worth keeping, transforming, or potentially dropping.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell G3 – Scatter plots for a few feature pairs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pairs = [\n",
    "    (\"num_dependencies\", \"description_len\"),\n",
    "    (\"num_requires_dist\", \"summary_len\"),\n",
    "    (\"num_scripts\", \"description_len\"),\n",
    "]\n",
    "\n",
    "for x_feat, y_feat in pairs:\n",
    "    if x_feat not in live_meta_df.columns or y_feat not in live_meta_df.columns:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    for label_val in [0, 1]:\n",
    "        subset = live_meta_df[live_meta_df[\"label_malicious\"] == label_val]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        plt.scatter(\n",
    "            subset[x_feat],\n",
    "            subset[y_feat],\n",
    "            alpha=0.7,\n",
    "            label=f\"label={label_val}\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(x_feat)\n",
    "    plt.ylabel(y_feat)\n",
    "    plt.title(f\"{y_feat} vs {x_feat} by label (live_meta_df)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af35b89",
   "metadata": {},
   "source": [
    "### Cell G3 – Pairwise relationships between static features\n",
    "\n",
    "Cell G3 steps up from 1D histograms to 2D relationships and shows **scatter plots of feature pairs**, coloured by label.\n",
    "\n",
    "- Each panel plots a pair of features such as:\n",
    "  - `num_dependencies` vs `description_len`\n",
    "  - `num_requires_dist` vs `summary_len`\n",
    "  - `num_scripts` vs `description_len`\n",
    "- Points are coloured by `label_malicious`, so we can see whether malicious versions form any **distinct clusters** or occupy particular regions of feature space (for example, “few dependencies but very long descriptions,” or “many dependencies plus non-empty scripts”).\n",
    "- With such a small dataset, we don’t expect perfectly separated clusters, but we *do* want to check:\n",
    "  - Are there obvious outliers that might be labelling or parsing errors?\n",
    "  - Do any simple visual rules pop out (“all malicious points fall into this corner”)?\n",
    "\n",
    "G3 is mainly about **intuition and anomaly-hunting**: it helps confirm that our feature engineering looks sensible and that any downstream model is not being driven by a handful of pathological points.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell G4 – Delta feature distributions for benign→* transitions\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if \"delta_live\" not in globals():\n",
    "    print(\"delta_live not found – run the delta-building cells first.\")\n",
    "else:\n",
    "    # Pick a few delta features to visualize\n",
    "    candidate_delta_feats = [\n",
    "        \"delta_num_requires_dist\",\n",
    "        \"delta_num_dependencies\",\n",
    "        \"delta_num_dev_dependencies\",\n",
    "        \"delta_summary_len\",\n",
    "        \"delta_description_len\",\n",
    "        \"delta_num_scripts\",\n",
    "    ]\n",
    "    plot_delta_feats = [d for d in candidate_delta_feats if d in delta_live.columns]\n",
    "\n",
    "    print(\"Plotting delta feature distributions for:\", plot_delta_feats)\n",
    "\n",
    "    for dfeat in plot_delta_feats:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "\n",
    "        benign_trans = delta_live[delta_live[\"y_malicious\"] == 0][dfeat].dropna()\n",
    "        mal_trans = delta_live[delta_live[\"y_malicious\"] == 1][dfeat].dropna()\n",
    "\n",
    "        all_vals = pd.concat([benign_trans, mal_trans])\n",
    "        if all_vals.empty:\n",
    "            print(f\"Skipping {dfeat}: no data.\")\n",
    "            plt.close()\n",
    "            continue\n",
    "\n",
    "        bins = np.histogram_bin_edges(all_vals, bins=15)\n",
    "\n",
    "        plt.hist(benign_trans, bins=bins, alpha=0.5, label=\"stay benign (0)\")\n",
    "        plt.hist(mal_trans, bins=bins, alpha=0.5, label=\"turn malicious (1)\")\n",
    "\n",
    "        plt.xlabel(dfeat)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"{dfeat}: benign→benign vs benign→malicious\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bcf00c",
   "metadata": {},
   "source": [
    "### Cell G4 – Delta feature distributions for benign→* transitions\n",
    "\n",
    "G4 repeats the idea from G2, but now on **delta features** derived from version differences (`delta_live`), where each row represents a transition from a previously benign version.\n",
    "\n",
    "- For each `delta_*` feature (e.g. `delta_num_dependencies`, `delta_num_dev_dependencies`, `delta_summary_len`, `delta_description_len`, `delta_num_scripts`), we plot two distributions:\n",
    "  - **“stay benign (0)”** – benign→benign transitions  \n",
    "  - **“turn malicious (1)”** – benign→malicious transitions\n",
    "- The x-axis is the *change* in that feature between the previous benign version and the current one. Values near zero mean “this field hardly changed across versions.”\n",
    "- Conceptually, these plots check whether **malicious transitions “move” differently** than benign ones:\n",
    "  - Do malicious upgrades tend to **add more dependencies** or **introduce scripts**?\n",
    "  - Do they show larger swings in **description or summary length**?\n",
    "\n",
    "G4 is the visual answer to: **“Does watching how metadata changes between versions add useful signal about maliciousness, beyond just looking at a single snapshot?”** It sets the stage for the simple delta-based classifier that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell G5 – Model ROC curve and feature importance (if model exists)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "if \"model\" not in globals():\n",
    "    print(\"No trained model found. Train the logistic regression pipeline first.\")\n",
    "else:\n",
    "    X = delta_live[delta_cols].fillna(0.0).astype(float)\n",
    "    y = delta_live[\"y_malicious\"].astype(int)\n",
    "\n",
    "    if y.nunique() < 2:\n",
    "        print(\"Only one class present in delta_live – ROC/importance not meaningful.\")\n",
    "    else:\n",
    "        # Pred proba on full dataset (or reuse X_test / y_test if you kept them)\n",
    "        y_proba = model.predict_proba(X)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y, y_proba)\n",
    "        auc = roc_auc_score(y, y_proba)\n",
    "\n",
    "        # ROC curve\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot(fpr, tpr, label=f\"ROC (AUC={auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC curve (benign→* delta model)\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Feature importance from logistic regression coefficients\n",
    "        lr = model.named_steps[\"logisticregression\"]\n",
    "        coef_df = pd.DataFrame({\n",
    "            \"feature\": delta_cols,\n",
    "            \"coef\": lr.coef_[0],\n",
    "        }).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "        top_k = 10\n",
    "        top_pos = coef_df.head(top_k)\n",
    "        top_neg = coef_df.tail(top_k)\n",
    "\n",
    "        # Positive coefficients: deltas that push towards \"malicious\"\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.barh(top_pos[\"feature\"], top_pos[\"coef\"])\n",
    "        plt.xlabel(\"Coefficient\")\n",
    "        plt.title(f\"Top {top_k} positive coefficients (towards malicious)\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Negative coefficients: deltas that push towards \"benign\"\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.barh(top_neg[\"feature\"], top_neg[\"coef\"])\n",
    "        plt.xlabel(\"Coefficient\")\n",
    "        plt.title(f\"Top {top_k} negative coefficients (towards benign)\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63fcac",
   "metadata": {},
   "source": [
    "### Cell G5 – Model ROC curve and feature importance\n",
    "\n",
    "#### ROC curve\n",
    "\n",
    "The first plot is the **Receiver Operating Characteristic (ROC) curve** for the current model:\n",
    "\n",
    "- The x-axis is the **False Positive Rate (FPR)**: proportion of benign samples incorrectly flagged as malicious.\n",
    "- The y-axis is the **True Positive Rate (TPR)**: proportion of malicious samples correctly detected.\n",
    "- The dashed diagonal line is the **random baseline** (a model that guesses malicious vs benign at random).\n",
    "- The solid curve shows how the model behaves as we sweep the decision threshold from “very strict” to “very loose,” and the legend reports the **Area Under the Curve (AUC)**.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- If the ROC curve lies substantially **above the diagonal**, the model is doing **better than random** at ranking malicious higher than benign.\n",
    "- The **AUC** summarizes this into a single number in \\[0.5, 1.0\\]:  \n",
    "  - ~0.5 ≈ random guessing  \n",
    "  - closer to 1.0 ≈ strong separation\n",
    "- In this notebook we’re plotting ROC on the **same data used to fit the model**, so this is mainly a **sanity check** that the model learned *some* signal. A proper evaluation would use a held-out test set or cross-validation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Feature importance (logistic regression coefficients)\n",
    "\n",
    "The next two bar charts use the **logistic regression coefficients** as a proxy for feature importance.\n",
    "\n",
    "Since the model is linear and we’ve standardised the input features:\n",
    "\n",
    "- Each `delta_*` feature gets a **coefficient**.\n",
    "- A **positive coefficient** means “increasing this feature pushes the prediction towards *malicious*.”\n",
    "- A **negative coefficient** means “increasing this feature pushes the prediction towards *benign*.”\n",
    "\n",
    "The notebook visualises:\n",
    "\n",
    "1. **Top positive coefficients (“towards malicious”)**  \n",
    "   - These are the delta features whose increase is most associated with the malicious label.  \n",
    "   - For example, a strongly positive coefficient on something like `delta_num_dependencies` would mean that versions which **suddenly gain dependencies** compared to their previous benign version are more suspicious.\n",
    "\n",
    "2. **Top negative coefficients (“towards benign”)**  \n",
    "   - These are delta features whose increase is most associated with *staying benign*.  \n",
    "   - For example, a strong negative coefficient on a “delta” feature would suggest that that type of change is characteristic of normal evolution rather than an attack.\n",
    "\n",
    "Reading these plots:\n",
    "\n",
    "- Look at **which `delta_*` fields show up near the top** of each bar chart; those are the features the model leans on most heavily.\n",
    "- Remember that coefficients capture **direction and relative strength**, not causal truth:\n",
    "  - Correlated features can share credit or blame.\n",
    "  - With so few samples, some coefficients may be unstable or noisy.\n",
    "\n",
    "Overall, G5 answers two questions:\n",
    "\n",
    "1. **Does the current model behave sensibly at all, compared to random guessing?** (ROC / AUC)\n",
    "2. **Which *changes in metadata* are the strongest directional signals of a version turning malicious vs staying benign?** (positive vs negative coefficients)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
